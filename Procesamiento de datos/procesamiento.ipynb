{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Importación de librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerías para el análisis de datos\n",
    "import numpy as np  # Biblioteca para operaciones numéricas, especialmente útil para trabajar con matrices y arrays\n",
    "import pandas as pd  # Biblioteca para manipulación y análisis de datos, especialmente para DataFrames\n",
    "import statsmodels.api as sm  # Biblioteca para realizar modelos estadísticos, útil para regresiones y otros análisis estadísticos\n",
    "from collections import Counter  # Contador de elementos en colecciones, útil para contar la frecuencia de elementos en una lista o array\n",
    "\n",
    "# Librería para optimización\n",
    "from gurobipy import Model, GRB, quicksum  # Gurobi es una biblioteca de optimización matemática. \n",
    "# Model permite definir el modelo de optimización,\n",
    "# GRB contiene constantes (como tipos de variables y sentido de optimización),\n",
    "# quicksum permite realizar sumas de forma rápida y eficiente en Gurobi.\n",
    "\n",
    "# Librerías operacionales\n",
    "import os  # Biblioteca para interactuar con el sistema operativo (ej. manejo de archivos y rutas)\n",
    "from datetime import datetime  # Módulo para trabajar con fechas y tiempos, útil para capturar fechas actuales o manipular datos de tiempo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h2>1. Carga de datos desde excel a dataframes de pandas</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar se cargan los datos iniciales desde los csv que nos proveen. (Esto puede tardar un ratito)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_tratamiento = 'https://drive.usercontent.google.com/download?id=1KTRwYGaWoQQnZwbk8VpdxKULMaOReoF5&authuser=0&confirm=t&uuid=4e4d7983-c5a5-412d-9f5b-b9bda1068b73&at=AENtkXZSxkDr84kWrDlz6ANq4ov2%3A1730951312566'\n",
    "\n",
    "df_tratamiento = pd.read_csv(\"Tratamiento.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_id = '173bRZQG7NWfdpHJ-o4-NA3ieH1-Fhyok'\n",
    "url_informacion_de_clientes = f'https://drive.google.com/uc?id={file_id}'\n",
    "\n",
    "df_informacion_de_clientes = pd.read_csv(\"Informacion_Clientes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_simulaciones_clientes = 'https://drive.usercontent.google.com/download?id=1IXyKwtKFLCUsAV1MtNqktiwKaHzV2D5A&authuser=0&confirm=t&uuid=edd22376-238f-4c1f-b603-728b07bafd7f&at=AENtkXaEURpV52p_BdWxyisvjhSQ%3A1730951026384'\n",
    "\n",
    "df_simulaciones_clientes = pd.read_csv(\"Simulaciones_clientes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_id = '1Z4jMzZeD2q-4-ioSgyimppAdLZzqDkt3'\n",
    "url_ventas = f'https://drive.google.com/uc?id={file_id}'\n",
    "\n",
    "df_ventas = pd.read_csv(\"Ventas.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <h3>1.1 Carga de 'Informacion_Clientes.csv'</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar se cargará la información de los clientes. Esto incluye las siguientes características de los clientes:\n",
    "\n",
    "* **unnamed**: algo como uid\n",
    "* **Rut**: identificador de Chile (supongo que por privacidad va desde 0 a max de observaciones)\n",
    "* **Género**: Masculino o femenino\n",
    "* **Categoría_Digital**: Si el cliente es digital o no\n",
    "* **Elasticidad_Precios**: Baja, media o alta\n",
    "* **Nacionalidad**: Chileno o extranjero\n",
    "* **Propensión**: Número entre 0 y 1 que idica que tan propenso a cursar un credito es el cliente\n",
    "* **Probabilidad_No_Pago**: Número entre 0 y 1 que indica la probabilidad de que el cliente no pague la deuda\n",
    "* **Edad**: Numero entero de edad en años\n",
    "* **Renta**: Renta promedio de los últimos 12 meses\n",
    "* **Oferta_Consumo**: Monto máximo que puede cursar un cliente dado sus antecedentes crediticios y situación socioeconómica. \n",
    "* **Deuda_CMF**: Deuda que tiene el cliente en otros bancos. Efectivamente es deuda pendiente, pero de créditos otorgados por la competencia.\n",
    "* **Tiempo_como_cliente**: Número de tiempo(no sé en que medida está) que el cliente lleva en el banco\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se elimina el tiempo como cliente ya que no aporta información"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_informacion_de_clientes.drop(columns=['Tiempo_como_cliente'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <h3>1.2 Carga de 'Simulaciones_Clientes.csv'</h3>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En segundo lugar se cargaran las simulaciones hechas por los clientes en la página del banco. Esto incluye las siguientes características de las simulaciones:\n",
    "* **unnamed**: Supongo que es el número de simulacion registrada, un tipo de identificador de la simulación\n",
    "* **fecha**: yyyy-mm-dd fecha de la simulación\n",
    "* **rut**: identificador de Chile del cliente que hizo la simulacion\n",
    "* **monto_simulado**: monto prestado al cliente\n",
    "* **plazo_simulado**: plazo en **meses** del crédito\n",
    "* **tasa_simulado**: costo para el cliente del credito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_simulaciones_clientes = df_simulaciones_clientes[df_simulaciones_clientes['Monto_Simulado'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <h3>1.3 Carga de 'Tratamiento.csv'</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En tercer lugar se cargara el tratamiento que ha tenido el banco con el cliente, es decir, cómo se han contactado con él. Esto incluye las siguientes características:\n",
    "\n",
    "* **unnamed**: Número de tratamiento registrado\n",
    "* **fecha**: yyyy-mm-dd\n",
    "* **rut**: Identificador de Chile del cliente con el que se tiene el tipo de trato\n",
    "* **n_correos**: Cantidad de correos que se enviaron en el mes que sale la fecha. Es decir, si sele fecha '2024-03-01', correspondería a los correos enviados en marzo de 2024.\n",
    "* **asg_ejec**: Si el cliente tiene un ejecutivo asignado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <h3>1.4 Carga de 'Ventas.csv'</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último se cargaran las ventas que ha tenido el banco con el cliente. Esto incluye las siguientes características:\n",
    "\n",
    "* **unnamed**: Índice sin significado\n",
    "* **fecha**: yyyy-mm-dd -> fecha en la que se concretó la venta\n",
    "* **rut**: identificador de Chile del cliente al que se le concretó la venta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h2>2. Joints de datos<h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unir los DataFrames 'df_informacion_de_clientes' y 'df_simulaciones_clientes' en base a la columna 'rut'\n",
    "# El método 'how=\"left\"' asegura que todos los registros de 'df_informacion_de_clientes' se conserven,\n",
    "# incluso si no tienen coincidencia en 'df_simulaciones_clientes'.\n",
    "df_simulaciones_e_informacion_de_clientes = pd.merge(\n",
    "    df_informacion_de_clientes, \n",
    "    df_simulaciones_clientes, \n",
    "    on='rut', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Crear una nueva columna 'simulo' que indica si el cliente tiene un 'Monto_Simulado' o no\n",
    "# El método 'notna()' devuelve True para valores no nulos y False para nulos.\n",
    "# Luego, 'astype(int)' convierte estos valores booleanos en enteros (1 para True, 0 para False).\n",
    "df_simulaciones_e_informacion_de_clientes['simulo'] = df_simulaciones_e_informacion_de_clientes['Monto_Simulado'].notna().astype(int)\n",
    "\n",
    "# Eliminar columnas innecesarias 'Unnamed: 0_x' y 'Unnamed: 0_y' que podrían haber surgido durante la carga o manipulación de datos\n",
    "df_simulaciones_e_informacion_de_clientes.drop(columns=['Unnamed: 0_x', 'Unnamed: 0_y'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unir los DataFrames 'df_simulaciones_e_informacion_de_clientes' y 'df_ventas' en base a las columnas 'rut' y 'fecha'\n",
    "# El método 'how=\"left\"' asegura que todos los registros de 'df_simulaciones_e_informacion_de_clientes' se conserven,\n",
    "# incluso si no tienen coincidencia en 'df_ventas'.\n",
    "df_simulaciones_e_informacion_de_clientes_ventas = pd.merge( \n",
    "    df_simulaciones_e_informacion_de_clientes, \n",
    "    df_ventas, \n",
    "    on=['rut', 'fecha'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Crear una nueva columna 'venta' que indica si existe una venta asociada al cliente y la fecha específica\n",
    "# El método 'notna()' verifica si hay un valor no nulo en la columna 'Unnamed: 0' (que indica presencia de una venta)\n",
    "# Luego, 'astype(int)' convierte estos valores booleanos en enteros (1 para True, 0 para False).\n",
    "df_simulaciones_e_informacion_de_clientes_ventas['venta'] = df_simulaciones_e_informacion_de_clientes_ventas['Unnamed: 0'].notna().astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unir los DataFrames 'df_simulaciones_e_informacion_de_clientes_ventas' y 'df_tratamiento' en base a las columnas 'rut' y 'fecha'\n",
    "# La unión se realiza con 'how=\"left\"' para conservar todos los registros de 'df_simulaciones_e_informacion_de_clientes_ventas'\n",
    "# incluso si no tienen coincidencia en 'df_tratamiento'.\n",
    "df_simulaciones_e_informacion_de_clientes_ventas_tratamiento = pd.merge( \n",
    "    df_simulaciones_e_informacion_de_clientes_ventas, \n",
    "    df_tratamiento, \n",
    "    on=['rut', 'fecha'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Renombrar la columna 'Unnamed: 0_x' a 'venta' para tener una denominación clara y comprensible.\n",
    "df_simulaciones_e_informacion_de_clientes_ventas_tratamiento.rename(columns={'Unnamed: 0_x': 'venta'}, inplace=True)\n",
    "\n",
    "# Actualizar la columna 'venta' para que indique si el registro de venta no es nulo (1 si hay venta, 0 si no hay)\n",
    "# Se utiliza 'notna()' para verificar la presencia de un valor y 'astype(int)' para convertir el resultado booleano a entero.\n",
    "df_simulaciones_e_informacion_de_clientes_ventas_tratamiento['venta'] = df_simulaciones_e_informacion_de_clientes_ventas_tratamiento['venta'].notna().astype(int)\n",
    "\n",
    "# Crear una nueva columna 'mes' que extrae el mes y año de la columna 'fecha'\n",
    "# Primero se convierte 'fecha' al formato datetime, luego 'dt.to_period('M')' obtiene el periodo del mes/año.\n",
    "df_simulaciones_e_informacion_de_clientes_ventas_tratamiento['mes'] = pd.to_datetime(df_simulaciones_e_informacion_de_clientes_ventas_tratamiento['fecha']).dt.to_period('M')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. CLUSTERING POR POLITICAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seteo de cluster. Aquí se definen las variables y sus cortes. La idea es que el algoritmo de RL haga sus acciones en esta sección"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí se definen que variables se utilizarán para crear el cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_informacion_de_clientes_procesados_cluster_definitivo = df_informacion_de_clientes[['rut', 'Renta', 'Elasticidad_Precios', 'Probabilidad_No_Pago']].copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui se definen en que partes y en cuantas partes se particionarán las variables escogidas anteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rut</th>\n",
       "      <th>Renta</th>\n",
       "      <th>Elasticidad_Precios</th>\n",
       "      <th>Probabilidad_No_Pago</th>\n",
       "      <th>Categoria_Probabilidad_No_Pago</th>\n",
       "      <th>Categoria_Renta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6.258183e+05</td>\n",
       "      <td>Alta</td>\n",
       "      <td>0.028445</td>\n",
       "      <td>Malos pagadores</td>\n",
       "      <td>Mejores Pagadores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.172616e+05</td>\n",
       "      <td>Baja</td>\n",
       "      <td>0.014320</td>\n",
       "      <td>Malos pagadores</td>\n",
       "      <td>Mejores Pagadores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.240551e+07</td>\n",
       "      <td>Baja</td>\n",
       "      <td>0.002156</td>\n",
       "      <td>Mejores Pagadores</td>\n",
       "      <td>Rentas bajas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5.441466e+05</td>\n",
       "      <td>Alta</td>\n",
       "      <td>0.034418</td>\n",
       "      <td>Malos pagadores</td>\n",
       "      <td>Mejores Pagadores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.870225e+05</td>\n",
       "      <td>Media</td>\n",
       "      <td>0.014978</td>\n",
       "      <td>Malos pagadores</td>\n",
       "      <td>Mejores Pagadores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543646</th>\n",
       "      <td>543647</td>\n",
       "      <td>1.176598e+05</td>\n",
       "      <td>Baja</td>\n",
       "      <td>0.037291</td>\n",
       "      <td>Malos pagadores</td>\n",
       "      <td>Mejores Pagadores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543647</th>\n",
       "      <td>543648</td>\n",
       "      <td>1.558612e+06</td>\n",
       "      <td>Baja</td>\n",
       "      <td>0.035877</td>\n",
       "      <td>Malos pagadores</td>\n",
       "      <td>Rentas bajas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543648</th>\n",
       "      <td>543649</td>\n",
       "      <td>9.449508e+05</td>\n",
       "      <td>Media</td>\n",
       "      <td>0.023306</td>\n",
       "      <td>Malos pagadores</td>\n",
       "      <td>Rentas bajas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543649</th>\n",
       "      <td>543650</td>\n",
       "      <td>1.039964e+06</td>\n",
       "      <td>Media</td>\n",
       "      <td>0.015121</td>\n",
       "      <td>Malos pagadores</td>\n",
       "      <td>Rentas bajas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543650</th>\n",
       "      <td>543651</td>\n",
       "      <td>4.728067e+05</td>\n",
       "      <td>Media</td>\n",
       "      <td>0.019647</td>\n",
       "      <td>Malos pagadores</td>\n",
       "      <td>Mejores Pagadores</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>543651 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           rut         Renta Elasticidad_Precios  Probabilidad_No_Pago  \\\n",
       "0            1  6.258183e+05                Alta              0.028445   \n",
       "1            2  3.172616e+05                Baja              0.014320   \n",
       "2            3  1.240551e+07                Baja              0.002156   \n",
       "3            4  5.441466e+05                Alta              0.034418   \n",
       "4            5  1.870225e+05               Media              0.014978   \n",
       "...        ...           ...                 ...                   ...   \n",
       "543646  543647  1.176598e+05                Baja              0.037291   \n",
       "543647  543648  1.558612e+06                Baja              0.035877   \n",
       "543648  543649  9.449508e+05               Media              0.023306   \n",
       "543649  543650  1.039964e+06               Media              0.015121   \n",
       "543650  543651  4.728067e+05               Media              0.019647   \n",
       "\n",
       "       Categoria_Probabilidad_No_Pago    Categoria_Renta  \n",
       "0                     Malos pagadores  Mejores Pagadores  \n",
       "1                     Malos pagadores  Mejores Pagadores  \n",
       "2                   Mejores Pagadores       Rentas bajas  \n",
       "3                     Malos pagadores  Mejores Pagadores  \n",
       "4                     Malos pagadores  Mejores Pagadores  \n",
       "...                               ...                ...  \n",
       "543646                Malos pagadores  Mejores Pagadores  \n",
       "543647                Malos pagadores       Rentas bajas  \n",
       "543648                Malos pagadores       Rentas bajas  \n",
       "543649                Malos pagadores       Rentas bajas  \n",
       "543650                Malos pagadores  Mejores Pagadores  \n",
       "\n",
       "[543651 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear una copia del DataFrame 'df_informacion_de_clientes_procesados_cluster_definitivo' para trabajar sin modificar el original\n",
    "df = df_informacion_de_clientes_procesados_cluster_definitivo.copy()\n",
    "\n",
    "\n",
    "# Ordenar el DataFrame por 'Probabilidad_No_Pago' en orden ascendente\n",
    "df_sorted = df.sort_values(by='Probabilidad_No_Pago')\n",
    "\n",
    "# Seleccionar los primeros 205000 clientes con la menor 'Probabilidad_No_Pago'\n",
    "mejores_pagadores = df_sorted.head(205000)\n",
    "\n",
    "# Añadir una columna 'Grupo_Pago' al DataFrame original, inicializando con 'Otros'\n",
    "df['Categoria_Probabilidad_No_Pago'] = 'Malos pagadores'\n",
    "\n",
    "# Asignar la etiqueta 'Mejores Pagadores' a los clientes seleccionados\n",
    "df.loc[mejores_pagadores.index, 'Categoria_Probabilidad_No_Pago'] = 'Mejores Pagadores'\n",
    "\n",
    "\n",
    "# Ordenar el DataFrame por 'Renta' en orden ascendente\n",
    "df_sorted = df.sort_values(by='Renta')\n",
    "\n",
    "# Seleccionar los primeros 205000 clientes con la menor 'Probabilidad_No_Pago'\n",
    "mejores_rentas = df_sorted.head(205000)\n",
    "\n",
    "# Añadir una columna 'Grupo_Pago' al DataFrame original, inicializando con 'Otros'\n",
    "df['Categoria_Renta'] = 'Rentas bajas'\n",
    "\n",
    "# Asignar la etiqueta 'Mejores Pagadores' a los clientes seleccionados\n",
    "df.loc[mejores_rentas.index, 'Categoria_Renta'] = 'Mejores Pagadores'\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenar las variables especificadas en una nueva columna 'categoria_clusterizacion'\n",
    "# La columna resultante combinará varias categorías en una descripción detallada del perfil del cliente.\n",
    "# Convertimos cada columna a tipo string para asegurarnos de que los datos sean compatibles para la concatenación.\n",
    "\n",
    "df['categoria_clusterizacion'] = ('Cliente con elasticidad' +\n",
    "    df['Elasticidad_Precios'].astype(str) + ' que es ' +              # Categoría de elasticidad del cliente\n",
    "    df['Categoria_Probabilidad_No_Pago'].astype(str) + ' con una ' +     # Categoría de propensión, seguida de \"con una\"\n",
    "    df['Categoria_Renta'].astype(str)                        # Categoría de renta\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asignar un número único a cada entrada distinta en la columna 'categoria_clusterizacion'\n",
    "# Se convierte la columna a tipo 'category', lo cual facilita la asignación de códigos numéricos únicos.\n",
    "# 'cat.codes' asigna un código numérico único para cada valor único de 'categoria_clusterizacion'.\n",
    "df['categoria_clusterizacion_numerica'] = df['categoria_clusterizacion'].astype('category').cat.codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una copia del DataFrame con solo las columnas 'rut', 'categoria_clusterizacion' y 'categoria_clusterizacion_numerica'\n",
    "# Esta copia se almacena en el nuevo DataFrame 'asignacion_clusters', el cual contendrá únicamente la identificación del cliente (rut),\n",
    "# la descripción del perfil ('categoria_clusterizacion') y el código numérico asignado a cada perfil ('categoria_clusterizacion_numerica').\n",
    "asignacion_clusters = df[['rut', 'categoria_clusterizacion', 'categoria_clusterizacion_numerica']].copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Estimacion de curvas de elasticidad por cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar una unión entre 'df_simulaciones_e_informacion_de_clientes_ventas' y 'asignacion_clusters' usando la columna 'rut' como clave\n",
    "# Esta unión ('merge') se realiza con 'how=\"left\"', lo que asegura que todos los registros de 'df_simulaciones_e_informacion_de_clientes_ventas' \n",
    "# se conserven, incluyendo aquellos sin coincidencia en 'asignacion_clusters'.\n",
    "# La finalidad es agregar la información de clusterización (categoría y código numérico) al DataFrame de simulaciones y ventas.\n",
    "df_estimar_elasticidad = pd.merge(df_simulaciones_e_informacion_de_clientes_ventas, asignacion_clusters, on='rut', how='left')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Este código realiza un análisis de elasticidad de ingresos en función de clusters de clientes. Primero, agrupa los datos por clusters definidos a través de variables de segmentación y filtra solo los datos relevantes para cada cluster. Luego, para cada cluster, se ajusta un modelo de regresión logística para predecir la probabilidad de aceptación de una simulación de crédito en función de la tasa de interés. A partir de este modelo, se crea una cuadrícula de tasas para estimar la probabilidad de aceptación y calcular el revenue potencial de cada simulación, teniendo en cuenta el monto medio simulado, el plazo medio simulado y la probabilidad media de no pago del cluster. Posteriormente, se determina la tasa que maximiza el revenue esperado y se calcula el número esperado de créditos aceptados, junto con el número de clientes únicos en cada cluster. Finalmente, los resultados se agregan tanto en listas globales como en un nuevo DataFrame, y luego se integran en el DataFrame original df_estimar_elasticidad, lo que permite analizar el revenue esperado total y otros indicadores clave en cada cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0:\n",
      "- Precio Máx. Revenue Esperado = 2.50%\n",
      "- Revenue Esperado Máximo = 743,866,611.30\n",
      "- Número de clientes en el cluster = 39964\n",
      "- Número de simulaciones en el cluster = 9176.47\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.4015\n",
      "- Número esperado de créditos aceptados = 3684\n",
      "- Monto medio simulado = 526,521.07\n",
      "- Plazo medio simulado = 27.48\n",
      "- Probabilidad de no pago media = 0.0281\n",
      "\n",
      "Cluster 4:\n",
      "- Precio Máx. Revenue Esperado = 1.00%\n",
      "- Revenue Esperado Máximo = 1,384,106,953.63\n",
      "- Número de clientes en el cluster = 49001\n",
      "- Número de simulaciones en el cluster = 11468.29\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.7431\n",
      "- Número esperado de créditos aceptados = 8522\n",
      "- Monto medio simulado = 1,120,980.25\n",
      "- Plazo medio simulado = 27.50\n",
      "- Probabilidad de no pago media = 0.0262\n",
      "\n",
      "Cluster 7:\n",
      "- Precio Máx. Revenue Esperado = 1.00%\n",
      "- Revenue Esperado Máximo = 41,886,293,892.75\n",
      "- Número de clientes en el cluster = 82633\n",
      "- Número de simulaciones en el cluster = 21163.65\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.7432\n",
      "- Número esperado de créditos aceptados = 15729\n",
      "- Monto medio simulado = 17,984,140.09\n",
      "- Plazo medio simulado = 27.49\n",
      "- Probabilidad de no pago media = 0.0042\n",
      "\n",
      "Cluster 8:\n",
      "- Precio Máx. Revenue Esperado = 1.38%\n",
      "- Revenue Esperado Máximo = 1,034,550,475.57\n",
      "- Número de clientes en el cluster = 54192\n",
      "- Número de simulaciones en el cluster = 12380.38\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.6132\n",
      "- Número esperado de créditos aceptados = 7591\n",
      "- Monto medio simulado = 673,059.77\n",
      "- Plazo medio simulado = 27.51\n",
      "- Probabilidad de no pago media = 0.0270\n",
      "\n",
      "Cluster 6:\n",
      "- Precio Máx. Revenue Esperado = 1.00%\n",
      "- Revenue Esperado Máximo = 758,093,290.07\n",
      "- Número de clientes en el cluster = 27044\n",
      "- Número de simulaciones en el cluster = 6634.18\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.7428\n",
      "- Número esperado de créditos aceptados = 4928\n",
      "- Monto medio simulado = 1,039,519.90\n",
      "- Plazo medio simulado = 27.49\n",
      "- Probabilidad de no pago media = 0.0046\n",
      "\n",
      "Cluster 9:\n",
      "- Precio Máx. Revenue Esperado = 1.38%\n",
      "- Revenue Esperado Máximo = 11,560,425,667.04\n",
      "- Número de clientes en el cluster = 69537\n",
      "- Número de simulaciones en el cluster = 15940.45\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.6119\n",
      "- Número esperado de créditos aceptados = 9754\n",
      "- Monto medio simulado = 5,835,016.45\n",
      "- Plazo medio simulado = 27.54\n",
      "- Probabilidad de no pago media = 0.0250\n",
      "\n",
      "Cluster 1:\n",
      "- Precio Máx. Revenue Esperado = 2.50%\n",
      "- Revenue Esperado Máximo = 8,538,810,147.52\n",
      "- Número de clientes en el cluster = 51959\n",
      "- Número de simulaciones en el cluster = 11946.64\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.4009\n",
      "- Número esperado de créditos aceptados = 4790\n",
      "- Monto medio simulado = 4,649,074.58\n",
      "- Plazo medio simulado = 27.45\n",
      "- Probabilidad de no pago media = 0.0270\n",
      "\n",
      "Cluster 5:\n",
      "- Precio Máx. Revenue Esperado = 1.00%\n",
      "- Revenue Esperado Máximo = 14,606,115,014.62\n",
      "- Número de clientes en el cluster = 73452\n",
      "- Número de simulaciones en el cluster = 17791.21\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.7432\n",
      "- Número esperado de créditos aceptados = 13222\n",
      "- Monto medio simulado = 7,578,012.00\n",
      "- Plazo medio simulado = 27.53\n",
      "- Probabilidad de no pago media = 0.0209\n",
      "\n",
      "Cluster 11:\n",
      "- Precio Máx. Revenue Esperado = 1.38%\n",
      "- Revenue Esperado Máximo = 21,899,693,982.30\n",
      "- Número de clientes en el cluster = 41204\n",
      "- Número de simulaciones en el cluster = 9933.32\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.6123\n",
      "- Número esperado de créditos aceptados = 6082\n",
      "- Monto medio simulado = 17,362,187.46\n",
      "- Plazo medio simulado = 27.50\n",
      "- Probabilidad de no pago media = 0.0041\n",
      "\n",
      "Cluster 10:\n",
      "- Precio Máx. Revenue Esperado = 1.38%\n",
      "- Revenue Esperado Máximo = 476,631,488.51\n",
      "- Número de clientes en el cluster = 21454\n",
      "- Número de simulaciones en el cluster = 4970.91\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.6119\n",
      "- Número esperado de créditos aceptados = 3042\n",
      "- Monto medio simulado = 756,732.94\n",
      "- Plazo medio simulado = 27.50\n",
      "- Probabilidad de no pago media = 0.0046\n",
      "\n",
      "Cluster 3:\n",
      "- Precio Máx. Revenue Esperado = 2.50%\n",
      "- Revenue Esperado Máximo = 3,739,364,503.53\n",
      "- Número de clientes en el cluster = 19515\n",
      "- Número de simulaciones en el cluster = 4601.44\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.3998\n",
      "- Número esperado de créditos aceptados = 1840\n",
      "- Monto medio simulado = 5,164,840.18\n",
      "- Plazo medio simulado = 27.54\n",
      "- Probabilidad de no pago media = 0.0046\n",
      "\n",
      "Cluster 2:\n",
      "- Precio Máx. Revenue Esperado = 2.50%\n",
      "- Revenue Esperado Máximo = 276,898,247.23\n",
      "- Número de clientes en el cluster = 12949\n",
      "- Número de simulaciones en el cluster = 3028.48\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.3985\n",
      "- Número esperado de créditos aceptados = 1207\n",
      "- Monto medio simulado = 583,960.47\n",
      "- Plazo medio simulado = 27.50\n",
      "- Probabilidad de no pago media = 0.0046\n",
      "\n",
      "El revenue total esperado es: 106,904,850,274.08 con un total de 542904 clientes, 129,035.42 simulaciones, y 80391 créditos.\n"
     ]
    }
   ],
   "source": [
    "# Inicializar listas para almacenar resultados globales de revenue, clientes, créditos y simulaciones\n",
    "lista_revenue = []\n",
    "lista_clientes = []\n",
    "lista_creditos = []\n",
    "lista_simulaciones = []\n",
    "\n",
    "cluster_results = []  # Lista para almacenar resultados específicos de cada cluster\n",
    "\n",
    "# Obtener los números únicos de cada cluster\n",
    "cluster_numbers = df_estimar_elasticidad['categoria_clusterizacion_numerica'].unique()\n",
    "\n",
    "# Iterar sobre cada cluster identificado por 'categoria_clusterizacion_numerica'\n",
    "for cluster_num in cluster_numbers:\n",
    "    # Filtrar los datos correspondientes al cluster actual\n",
    "    df_cluster = df_estimar_elasticidad[df_estimar_elasticidad['categoria_clusterizacion_numerica'] == cluster_num]\n",
    "    \n",
    "    # Asegurarse de que existen datos para ambos casos: venta == 1 y venta == 0\n",
    "    if df_cluster.empty or df_cluster['venta'].isnull().all():\n",
    "        continue  # Saltar este cluster si no cumple con la condición\n",
    "    \n",
    "    # Remover filas donde 'venta' o 'Tasa_Simulado' son nulos o infinitos\n",
    "    df_cluster = df_cluster.replace([np.inf, -np.inf], np.nan)\n",
    "    df_cluster = df_cluster.dropna(subset=['venta', 'Tasa_Simulado', 'Plazo_Simulado', 'Monto_Simulado', 'Probabilidad_No_Pago'])\n",
    "    \n",
    "    # Saltar el cluster si no hay suficientes puntos de datos\n",
    "    if df_cluster.shape[0] < 10:\n",
    "        continue\n",
    "    \n",
    "    # Extraer las variables 'venta' (como variable dependiente) y 'Tasa_Simulado' (como predictor)\n",
    "    y = df_cluster['venta']\n",
    "    X = df_cluster[['Tasa_Simulado']]\n",
    "    \n",
    "    # Añadir un término constante para el intercepto\n",
    "    X = sm.add_constant(X)\n",
    "    \n",
    "    # Remover filas con valores NaN o Inf en X o y\n",
    "    is_finite = np.isfinite(X).all(1) & np.isfinite(y)\n",
    "    X = X[is_finite]\n",
    "    y = y[is_finite]\n",
    "    \n",
    "    # Asegurarse de que después de remover NaN/Inf, todavía hay suficientes datos\n",
    "    if len(y) < 10:\n",
    "        continue\n",
    "    \n",
    "    # Ajustar el modelo de regresión logística\n",
    "    logit_model = sm.Logit(y, X)\n",
    "    try:\n",
    "        result = logit_model.fit(disp=0)\n",
    "    except:\n",
    "        continue  # Saltar el cluster si el modelo no converge\n",
    "    \n",
    "    # Crear una cuadrícula de valores de 'Tasa_Simulado' para predicciones\n",
    "    tasa_min = df_cluster['Tasa_Simulado'].min()\n",
    "    tasa_max = df_cluster['Tasa_Simulado'].max()\n",
    "    tasas_grid = np.linspace(tasa_min, tasa_max, 1000)\n",
    "    \n",
    "    # Predecir la probabilidad de aceptación usando el modelo ajustado\n",
    "    X_grid = sm.add_constant(tasas_grid)\n",
    "    acceptance_probability = result.predict(X_grid)\n",
    "    \n",
    "    # Asegurar que las probabilidades están en el rango [0, 1]\n",
    "    acceptance_probability = np.clip(acceptance_probability, 0, 1)\n",
    "    \n",
    "    # Calcular valores medios necesarios para el cálculo de revenue\n",
    "    n = df_cluster['Plazo_Simulado'].mean()\n",
    "    vp = df_cluster['Monto_Simulado'].mean()\n",
    "    pnp = df_cluster['Probabilidad_No_Pago'].mean()\n",
    "    data = {\n",
    "        'Plazo_Simulado_medio': n, \n",
    "        'Monto_Simulado_medio': vp, \n",
    "        'Probabilidad_No_Pago_media': pnp\n",
    "    }\n",
    "    \n",
    "    # Calcular el revenue potencial\n",
    "    i = tasas_grid / 100  # Convertir a decimal\n",
    "    one_plus_i_pow_n = np.power(1 + i, n)\n",
    "    annuity_factor = (i * one_plus_i_pow_n) / (one_plus_i_pow_n - 1)\n",
    "    revenue = (n * vp * annuity_factor) - vp\n",
    "    potential_revenue = revenue * (1 - pnp)\n",
    "    \n",
    "    # Calcular el promedio de simulaciones por fecha\n",
    "    df_cluster_simulaciones_1 = df_cluster[df_cluster['simulo'] == 1]\n",
    "    num_dates = df_cluster_simulaciones_1['fecha'].nunique()\n",
    "    total_simulaciones = df_cluster_simulaciones_1['simulo'].sum()\n",
    "    simulaciones_medias = total_simulaciones / num_dates if num_dates else 0\n",
    "    \n",
    "    # Saltar el cluster si no hay simulaciones\n",
    "    if simulaciones_medias == 0:\n",
    "        continue\n",
    "    \n",
    "    # Calcular el revenue esperado\n",
    "    expected_revenue = acceptance_probability * potential_revenue * simulaciones_medias\n",
    "    \n",
    "    # Encontrar la tasa que maximiza el revenue esperado\n",
    "    idx_max = np.argmax(expected_revenue)\n",
    "    max_price = tasas_grid[idx_max]\n",
    "    max_expected_revenue = expected_revenue[idx_max]\n",
    "    \n",
    "    # Probabilidad de aceptación en la tasa óptima\n",
    "    prob_aceptacion_optima = acceptance_probability[idx_max]\n",
    "    \n",
    "    # Número esperado de créditos aceptados\n",
    "    num_creditos_aceptados = round(prob_aceptacion_optima * simulaciones_medias)\n",
    "    \n",
    "    # Número de clientes únicos en el cluster\n",
    "    num_clients = df_cluster['rut'].nunique()\n",
    "    \n",
    "    # Imprimir resultados para cada cluster\n",
    "    print(f'Cluster {cluster_num}:')\n",
    "    print(f'- Precio Máx. Revenue Esperado = {max_price:.2f}%')\n",
    "    print(f'- Revenue Esperado Máximo = {max_expected_revenue:,.2f}')\n",
    "    print(f'- Número de clientes en el cluster = {num_clients}')\n",
    "    print(f'- Número de simulaciones en el cluster = {simulaciones_medias:.2f}')\n",
    "    print(f'- Probabilidad de aceptación en el precio óptimo = {prob_aceptacion_optima:.4f}')\n",
    "    print(f'- Número esperado de créditos aceptados = {num_creditos_aceptados}')\n",
    "    print(f'- Monto medio simulado = {data[\"Monto_Simulado_medio\"]:,.2f}')\n",
    "    print(f'- Plazo medio simulado = {data[\"Plazo_Simulado_medio\"]:,.2f}')\n",
    "    print(f'- Probabilidad de no pago media = {data[\"Probabilidad_No_Pago_media\"]:.4f}\\n')\n",
    "    \n",
    "    # Agregar resultados a las listas globales\n",
    "    lista_clientes.append(num_clients)\n",
    "    lista_revenue.append(max_expected_revenue)\n",
    "    lista_creditos.append(num_creditos_aceptados)\n",
    "    lista_simulaciones.append(simulaciones_medias)\n",
    "    \n",
    "    # Almacenar resultados por cluster en cluster_results\n",
    "    cluster_results.append({\n",
    "        'categoria_clusterizacion_numerica': cluster_num,\n",
    "        'tasa_optima': max_price,\n",
    "        'probabilidad_aceptacion_optima': prob_aceptacion_optima,\n",
    "        'revenue_esperado_maximo': max_expected_revenue,\n",
    "        'numero_clientes': num_clients,\n",
    "        'numero_simulaciones_medias': simulaciones_medias,\n",
    "        'numero_creditos_esperados': num_creditos_aceptados,\n",
    "        'monto_medio_simulado': data[\"Monto_Simulado_medio\"],\n",
    "        'plazo_medio_simulado': data[\"Plazo_Simulado_medio\"],\n",
    "        'probabilidad_no_pago_media': data[\"Probabilidad_No_Pago_media\"]\n",
    "    })\n",
    "\n",
    "# Imprimir resultados globales\n",
    "total_revenue = sum(lista_revenue)\n",
    "total_clientes = sum(lista_clientes)\n",
    "total_simulaciones = sum(lista_simulaciones)\n",
    "total_creditos = sum(lista_creditos)\n",
    "\n",
    "print(f\"El revenue total esperado es: {total_revenue:,.2f} con un total de {total_clientes} clientes, \"\n",
    "      f\"{total_simulaciones:,.2f} simulaciones, y {total_creditos} créditos.\")\n",
    "\n",
    "# Crear un DataFrame a partir de cluster_results\n",
    "df_cluster_results = pd.DataFrame(cluster_results)\n",
    "\n",
    "# Incorporar los resultados por cluster de 'df_cluster_results' a 'df_estimar_elasticidad'\n",
    "df_estimar_elasticidad = df_estimar_elasticidad.merge(\n",
    "    df_cluster_results[['categoria_clusterizacion_numerica', 'tasa_optima', 'probabilidad_aceptacion_optima']],\n",
    "    on='categoria_clusterizacion_numerica', \n",
    "    how='left'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Estimacion de respuesta a tratamiento por cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unir los DataFrames 'df_tratamiento' y 'df_simulaciones_clientes' usando las columnas 'rut' y 'fecha' como claves\n",
    "# La unión se realiza con 'how=\"left\"', lo cual asegura que todos los registros de 'df_tratamiento' se conserven,\n",
    "# incluyendo aquellos sin coincidencia en 'df_simulaciones_clientes'.\n",
    "# Esta operación permite combinar la información de tratamiento con los datos de simulaciones de clientes.\n",
    "df_simulaciones_info = pd.merge(df_tratamiento, df_simulaciones_clientes, on=['rut', 'fecha'], how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usar operaciones de cadenas vectorizadas para crear la columna 'Tratamiento'\n",
    "# Esta columna concatenará información sobre el ejecutivo asignado y el número de correos enviados.\n",
    "# Se convierte 'asg_ejec' a string para poder concatenar, y 'n_correos' se convierte primero a entero y luego a string.\n",
    "# El formato final es: \"Ejecutivo=<valor_asg_ejec>, Correos=<valor_n_correos>\"\n",
    "df_simulaciones_info['Tratamiento'] = (\n",
    "    'Ejecutivo=' + df_simulaciones_info['asg_ejec'].astype(str) +\n",
    "    ', Correos=' + df_simulaciones_info['n_correos'].astype(int).astype(str)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0_x</th>\n",
       "      <th>fecha</th>\n",
       "      <th>rut</th>\n",
       "      <th>n_correos</th>\n",
       "      <th>asg_ejec</th>\n",
       "      <th>Unnamed: 0_y</th>\n",
       "      <th>Monto_Simulado</th>\n",
       "      <th>Plazo_Simulado</th>\n",
       "      <th>Tasa_Simulado</th>\n",
       "      <th>Tratamiento</th>\n",
       "      <th>mes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ejecutivo=0, Correos=3</td>\n",
       "      <td>2019-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543651</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ejecutivo=0, Correos=4</td>\n",
       "      <td>2019-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1087302</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-03-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ejecutivo=0, Correos=1</td>\n",
       "      <td>2019-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630953</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ejecutivo=0, Correos=3</td>\n",
       "      <td>2019-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2174604</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-05-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ejecutivo=0, Correos=0</td>\n",
       "      <td>2019-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33162711</th>\n",
       "      <td>0</td>\n",
       "      <td>2024-02-01</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ejecutivo=0, Correos=3</td>\n",
       "      <td>2024-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33706362</th>\n",
       "      <td>0</td>\n",
       "      <td>2024-03-01</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ejecutivo=0, Correos=3</td>\n",
       "      <td>2024-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34250013</th>\n",
       "      <td>0</td>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ejecutivo=0, Correos=2</td>\n",
       "      <td>2024-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34793664</th>\n",
       "      <td>0</td>\n",
       "      <td>2024-05-01</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7864785.0</td>\n",
       "      <td>267268.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2.027869</td>\n",
       "      <td>Ejecutivo=1, Correos=2</td>\n",
       "      <td>2024-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35337315</th>\n",
       "      <td>0</td>\n",
       "      <td>2024-06-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ejecutivo=0, Correos=1</td>\n",
       "      <td>2024-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Unnamed: 0_x       fecha  rut  n_correos  asg_ejec  Unnamed: 0_y  \\\n",
       "0                    0  2019-01-01    1          3         0           NaN   \n",
       "543651               0  2019-02-01    1          4         0           NaN   \n",
       "1087302              0  2019-03-01    1          1         0           NaN   \n",
       "1630953              0  2019-04-01    1          3         0           NaN   \n",
       "2174604              0  2019-05-01    1          0         0           NaN   \n",
       "...                ...         ...  ...        ...       ...           ...   \n",
       "33162711             0  2024-02-01    1          3         0           NaN   \n",
       "33706362             0  2024-03-01    1          3         0           NaN   \n",
       "34250013             0  2024-04-01    1          2         0           NaN   \n",
       "34793664             0  2024-05-01    1          2         1     7864785.0   \n",
       "35337315             0  2024-06-01    1          1         0           NaN   \n",
       "\n",
       "          Monto_Simulado  Plazo_Simulado  Tasa_Simulado  \\\n",
       "0                    NaN             NaN            NaN   \n",
       "543651               NaN             NaN            NaN   \n",
       "1087302              NaN             NaN            NaN   \n",
       "1630953              NaN             NaN            NaN   \n",
       "2174604              NaN             NaN            NaN   \n",
       "...                  ...             ...            ...   \n",
       "33162711             NaN             NaN            NaN   \n",
       "33706362             NaN             NaN            NaN   \n",
       "34250013             NaN             NaN            NaN   \n",
       "34793664        267268.0            31.0       2.027869   \n",
       "35337315             NaN             NaN            NaN   \n",
       "\n",
       "                     Tratamiento      mes  \n",
       "0         Ejecutivo=0, Correos=3  2019-01  \n",
       "543651    Ejecutivo=0, Correos=4  2019-02  \n",
       "1087302   Ejecutivo=0, Correos=1  2019-03  \n",
       "1630953   Ejecutivo=0, Correos=3  2019-04  \n",
       "2174604   Ejecutivo=0, Correos=0  2019-05  \n",
       "...                          ...      ...  \n",
       "33162711  Ejecutivo=0, Correos=3  2024-02  \n",
       "33706362  Ejecutivo=0, Correos=3  2024-03  \n",
       "34250013  Ejecutivo=0, Correos=2  2024-04  \n",
       "34793664  Ejecutivo=1, Correos=2  2024-05  \n",
       "35337315  Ejecutivo=0, Correos=1  2024-06  \n",
       "\n",
       "[66 rows x 11 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extraer el mes y año de la columna 'fecha' y crear una nueva columna 'mes' en formato de periodo mensual\n",
    "# Se convierte 'fecha' al formato datetime y luego se usa 'dt.to_period('M')' para obtener el mes/año.\n",
    "df_simulaciones_info['mes'] = pd.to_datetime(df_simulaciones_info['fecha']).dt.to_period('M')\n",
    "\n",
    "# Filtrar y mostrar las filas donde 'rut' es igual a 1\n",
    "# Este filtro permite observar los registros específicos del cliente con 'rut' igual a 1, \n",
    "# lo cual es útil para verificar datos o analizar un cliente en particular.\n",
    "df_simulaciones_info[df_simulaciones_info['rut'] == 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0_x</th>\n",
       "      <th>fecha</th>\n",
       "      <th>rut</th>\n",
       "      <th>n_correos</th>\n",
       "      <th>asg_ejec</th>\n",
       "      <th>Unnamed: 0_y</th>\n",
       "      <th>Monto_Simulado</th>\n",
       "      <th>Plazo_Simulado</th>\n",
       "      <th>Tasa_Simulado</th>\n",
       "      <th>Tratamiento</th>\n",
       "      <th>mes</th>\n",
       "      <th>simulo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ejecutivo=0, Correos=3</td>\n",
       "      <td>2019-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543651</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ejecutivo=0, Correos=4</td>\n",
       "      <td>2019-02</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1087302</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-03-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ejecutivo=0, Correos=1</td>\n",
       "      <td>2019-03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630953</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ejecutivo=0, Correos=3</td>\n",
       "      <td>2019-04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2174604</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-05-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ejecutivo=0, Correos=0</td>\n",
       "      <td>2019-05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33162711</th>\n",
       "      <td>0</td>\n",
       "      <td>2024-02-01</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ejecutivo=0, Correos=3</td>\n",
       "      <td>2024-02</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33706362</th>\n",
       "      <td>0</td>\n",
       "      <td>2024-03-01</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ejecutivo=0, Correos=3</td>\n",
       "      <td>2024-03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34250013</th>\n",
       "      <td>0</td>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ejecutivo=0, Correos=2</td>\n",
       "      <td>2024-04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34793664</th>\n",
       "      <td>0</td>\n",
       "      <td>2024-05-01</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7864785.0</td>\n",
       "      <td>267268.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2.027869</td>\n",
       "      <td>Ejecutivo=1, Correos=2</td>\n",
       "      <td>2024-05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35337315</th>\n",
       "      <td>0</td>\n",
       "      <td>2024-06-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ejecutivo=0, Correos=1</td>\n",
       "      <td>2024-06</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Unnamed: 0_x       fecha  rut  n_correos  asg_ejec  Unnamed: 0_y  \\\n",
       "0                    0  2019-01-01    1          3         0           NaN   \n",
       "543651               0  2019-02-01    1          4         0           NaN   \n",
       "1087302              0  2019-03-01    1          1         0           NaN   \n",
       "1630953              0  2019-04-01    1          3         0           NaN   \n",
       "2174604              0  2019-05-01    1          0         0           NaN   \n",
       "...                ...         ...  ...        ...       ...           ...   \n",
       "33162711             0  2024-02-01    1          3         0           NaN   \n",
       "33706362             0  2024-03-01    1          3         0           NaN   \n",
       "34250013             0  2024-04-01    1          2         0           NaN   \n",
       "34793664             0  2024-05-01    1          2         1     7864785.0   \n",
       "35337315             0  2024-06-01    1          1         0           NaN   \n",
       "\n",
       "          Monto_Simulado  Plazo_Simulado  Tasa_Simulado  \\\n",
       "0                    NaN             NaN            NaN   \n",
       "543651               NaN             NaN            NaN   \n",
       "1087302              NaN             NaN            NaN   \n",
       "1630953              NaN             NaN            NaN   \n",
       "2174604              NaN             NaN            NaN   \n",
       "...                  ...             ...            ...   \n",
       "33162711             NaN             NaN            NaN   \n",
       "33706362             NaN             NaN            NaN   \n",
       "34250013             NaN             NaN            NaN   \n",
       "34793664        267268.0            31.0       2.027869   \n",
       "35337315             NaN             NaN            NaN   \n",
       "\n",
       "                     Tratamiento      mes  simulo  \n",
       "0         Ejecutivo=0, Correos=3  2019-01       0  \n",
       "543651    Ejecutivo=0, Correos=4  2019-02       0  \n",
       "1087302   Ejecutivo=0, Correos=1  2019-03       0  \n",
       "1630953   Ejecutivo=0, Correos=3  2019-04       0  \n",
       "2174604   Ejecutivo=0, Correos=0  2019-05       0  \n",
       "...                          ...      ...     ...  \n",
       "33162711  Ejecutivo=0, Correos=3  2024-02       0  \n",
       "33706362  Ejecutivo=0, Correos=3  2024-03       0  \n",
       "34250013  Ejecutivo=0, Correos=2  2024-04       0  \n",
       "34793664  Ejecutivo=1, Correos=2  2024-05       1  \n",
       "35337315  Ejecutivo=0, Correos=1  2024-06       0  \n",
       "\n",
       "[66 rows x 12 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear una nueva columna 'simulo' para indicar si el cliente tiene un registro de simulación\n",
    "# La columna 'Unnamed: 0_y' se utiliza para verificar si hay un valor no nulo, lo que implica que hay una simulación.\n",
    "# 'notna()' devuelve True para valores no nulos y False para valores nulos; luego, 'astype(int)' convierte estos valores a 1 (True) o 0 (False).\n",
    "df_simulaciones_info['simulo'] = df_simulaciones_info['Unnamed: 0_y'].notna().astype(int)\n",
    "\n",
    "# Filtrar y mostrar las filas donde 'rut' es igual a 1\n",
    "# Este filtro permite observar los registros específicos del cliente con 'rut' igual a 1, \n",
    "# útil para verificar si la columna 'simulo' refleja correctamente la presencia de simulaciones para este cliente.\n",
    "df_simulaciones_info[df_simulaciones_info['rut'] == 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una copia del DataFrame 'df_estimar_elasticidad' con solo las columnas especificadas\n",
    "# 'df1' contiene las columnas 'rut', 'categoria_clusterizacion_numerica', 'tasa_optima' y 'probabilidad_aceptacion_optima'.\n",
    "# Esta copia es útil para trabajar con los datos de elasticidad y clusterización sin modificar el DataFrame original.\n",
    "df1 = df_estimar_elasticidad[['rut', 'categoria_clusterizacion_numerica', 'tasa_optima', 'probabilidad_aceptacion_optima']].copy()\n",
    "\n",
    "# Crear una copia del DataFrame 'df_simulaciones_info' con solo las columnas especificadas\n",
    "# 'df2' contiene las columnas 'rut', 'mes', 'Tratamiento' y 'simulo'.\n",
    "# Esta copia es útil para trabajar con los datos de tratamiento y simulación en un conjunto de datos reducido.\n",
    "df2 = df_simulaciones_info[['rut', 'mes', 'Tratamiento', 'simulo']].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categoria_clusterizacion_numerica</th>\n",
       "      <th>Tratamiento</th>\n",
       "      <th>probabilidad_simular</th>\n",
       "      <th>caso_favorable</th>\n",
       "      <th>caso_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Ejecutivo=0, Correos=0</td>\n",
       "      <td>0.142091</td>\n",
       "      <td>30963</td>\n",
       "      <td>217909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ejecutivo=0, Correos=1</td>\n",
       "      <td>0.154878</td>\n",
       "      <td>36370</td>\n",
       "      <td>234830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Ejecutivo=0, Correos=2</td>\n",
       "      <td>0.166170</td>\n",
       "      <td>30098</td>\n",
       "      <td>181128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Ejecutivo=0, Correos=3</td>\n",
       "      <td>0.173276</td>\n",
       "      <td>78393</td>\n",
       "      <td>452418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Ejecutivo=0, Correos=4</td>\n",
       "      <td>0.176019</td>\n",
       "      <td>127619</td>\n",
       "      <td>725028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>11</td>\n",
       "      <td>Ejecutivo=0, Correos=3</td>\n",
       "      <td>0.170259</td>\n",
       "      <td>71129</td>\n",
       "      <td>417770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>11</td>\n",
       "      <td>Ejecutivo=0, Correos=4</td>\n",
       "      <td>0.173859</td>\n",
       "      <td>116267</td>\n",
       "      <td>668742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>11</td>\n",
       "      <td>Ejecutivo=1, Correos=0</td>\n",
       "      <td>0.344585</td>\n",
       "      <td>43568</td>\n",
       "      <td>126436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>11</td>\n",
       "      <td>Ejecutivo=1, Correos=1</td>\n",
       "      <td>0.353329</td>\n",
       "      <td>48346</td>\n",
       "      <td>136830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>11</td>\n",
       "      <td>Ejecutivo=1, Correos=2</td>\n",
       "      <td>0.364088</td>\n",
       "      <td>286313</td>\n",
       "      <td>786384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    categoria_clusterizacion_numerica             Tratamiento  \\\n",
       "0                                   0  Ejecutivo=0, Correos=0   \n",
       "1                                   0  Ejecutivo=0, Correos=1   \n",
       "2                                   0  Ejecutivo=0, Correos=2   \n",
       "3                                   0  Ejecutivo=0, Correos=3   \n",
       "4                                   0  Ejecutivo=0, Correos=4   \n",
       "..                                ...                     ...   \n",
       "91                                 11  Ejecutivo=0, Correos=3   \n",
       "92                                 11  Ejecutivo=0, Correos=4   \n",
       "93                                 11  Ejecutivo=1, Correos=0   \n",
       "94                                 11  Ejecutivo=1, Correos=1   \n",
       "95                                 11  Ejecutivo=1, Correos=2   \n",
       "\n",
       "    probabilidad_simular  caso_favorable  caso_total  \n",
       "0               0.142091           30963      217909  \n",
       "1               0.154878           36370      234830  \n",
       "2               0.166170           30098      181128  \n",
       "3               0.173276           78393      452418  \n",
       "4               0.176019          127619      725028  \n",
       "..                   ...             ...         ...  \n",
       "91              0.170259           71129      417770  \n",
       "92              0.173859          116267      668742  \n",
       "93              0.344585           43568      126436  \n",
       "94              0.353329           48346      136830  \n",
       "95              0.364088          286313      786384  \n",
       "\n",
       "[96 rows x 5 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Paso 1: Preparación de datos y mapeo de clusters\n",
    "# Eliminar duplicados en 'df1' para tener un valor único de 'categoria_clusterizacion_numerica' por cada 'rut'.\n",
    "df1_unique = df1.drop_duplicates(subset='rut')\n",
    "\n",
    "# Crear un mapeo de 'rut' a 'categoria_clusterizacion_numerica' para asociar cada cliente a su cluster numérico.\n",
    "rut_cluster_map = df1_unique.set_index('rut')['categoria_clusterizacion_numerica']\n",
    "\n",
    "# Mapear la categoría de cluster a cada 'rut' en 'df2' usando el mapeo creado\n",
    "df2['categoria_clusterizacion_numerica'] = df2['rut'].map(rut_cluster_map)\n",
    "\n",
    "# Eliminar filas donde 'categoria_clusterizacion_numerica' es nulo, es decir, aquellos 'rut' sin mapeo de cluster.\n",
    "df2 = df2.dropna(subset=['categoria_clusterizacion_numerica'])\n",
    "\n",
    "# Conversión de tipos de datos\n",
    "# Convertir 'categoria_clusterizacion_numerica' a entero para garantizar un tipo de dato consistente.\n",
    "df2['categoria_clusterizacion_numerica'] = df2['categoria_clusterizacion_numerica'].astype(int)\n",
    "\n",
    "# Convertir 'simulo' a numérico, reemplazando valores nulos por 0 y asegurando que sea un tipo de dato entero.\n",
    "df2['simulo'] = pd.to_numeric(df2['simulo'], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "# Convertir 'Tratamiento' a tipo de categoría para optimizar espacio y realizar operaciones categóricas.\n",
    "df2['Tratamiento'] = df2['Tratamiento'].astype('category')\n",
    "\n",
    "# Paso 2: Calcular el caso total (entradas por tratamiento sin importar el valor de 'simulo')\n",
    "# Agrupar por 'categoria_clusterizacion_numerica' y 'Tratamiento' para contar el número total de registros en cada combinación.\n",
    "total_entries_per_cluster_treatment = df2.groupby(['categoria_clusterizacion_numerica', 'Tratamiento']).size().reset_index(name='caso_total')\n",
    "\n",
    "# Paso 3: Calcular el caso favorable (entradas por tratamiento cuando 'simulo' == 1)\n",
    "# Filtrar filas donde 'simulo' es 1 (clientes que realizaron una simulación)\n",
    "df_simulations = df2[df2['simulo'] == 1]\n",
    "\n",
    "# Agrupar por 'categoria_clusterizacion_numerica' y 'Tratamiento' para contar el número de registros favorables (simulaciones).\n",
    "favorable_entries_per_cluster_treatment = df_simulations.groupby(['categoria_clusterizacion_numerica', 'Tratamiento']).size().reset_index(name='caso_favorable')\n",
    "\n",
    "# Paso 4: Calcular la probabilidad de simulación como caso favorable / caso total\n",
    "# Realizar un merge entre 'total_entries_per_cluster_treatment' y 'favorable_entries_per_cluster_treatment' en las columnas de cluster y tratamiento.\n",
    "df_probabilities = total_entries_per_cluster_treatment.merge(\n",
    "    favorable_entries_per_cluster_treatment,\n",
    "    on=['categoria_clusterizacion_numerica', 'Tratamiento'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Llenar valores nulos en 'caso_favorable' con 0, asegurando que solo las columnas numéricas estén afectadas.\n",
    "df_probabilities['caso_favorable'] = df_probabilities['caso_favorable'].fillna(0).astype(int)\n",
    "\n",
    "# Asegurar que 'caso_total' sea de tipo entero para evitar inconsistencias en los conteos.\n",
    "df_probabilities['caso_total'] = df_probabilities['caso_total'].astype(int)\n",
    "\n",
    "# Calcular la probabilidad de simulación como el cociente entre 'caso_favorable' y 'caso_total'.\n",
    "df_probabilities['probabilidad_simular'] = df_probabilities['caso_favorable'] / df_probabilities['caso_total']\n",
    "\n",
    "# Organizar las columnas del DataFrame resultante para facilitar su análisis.\n",
    "df_probabilities = df_probabilities[[\n",
    "    'categoria_clusterizacion_numerica',\n",
    "    'Tratamiento',\n",
    "    'probabilidad_simular',\n",
    "    'caso_favorable',\n",
    "    'caso_total'\n",
    "]]\n",
    "\n",
    "# Mostrar el DataFrame resultante con la probabilidad de simulación calculada para cada combinación de cluster y tratamiento.\n",
    "df_probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar el DataFrame 'df_estimar_elasticidad' para revisar su contenido antes de realizar cálculos adicionales\n",
    "df_estimar_elasticidad\n",
    "\n",
    "# Calcular el valor promedio de 'Monto_Simulado' para cada 'categoria_clusterizacion_numerica'\n",
    "# Usamos 'groupby' para agrupar por 'categoria_clusterizacion_numerica' y 'transform(\"mean\")' para calcular el promedio.\n",
    "# Luego, 'transform' asigna este valor promedio a cada fila dentro de su grupo, creando una columna 'Monto_Simulado_mean' con estos promedios.\n",
    "df_estimar_elasticidad['Monto_Simulado_mean'] = df_estimar_elasticidad.groupby('categoria_clusterizacion_numerica')['Monto_Simulado'].transform('mean')\n",
    "\n",
    "# Calcular el valor promedio de 'Plazo_Simulado' para cada 'categoria_clusterizacion_numerica'\n",
    "# Similar al cálculo anterior, 'groupby' agrupa los datos por 'categoria_clusterizacion_numerica', y 'transform(\"mean\")' calcula el promedio.\n",
    "# Se asigna el promedio resultante a cada fila dentro del grupo en la nueva columna 'Plazo_Simulado_mean'.\n",
    "df_estimar_elasticidad['Plazo_Simulado_mean'] = df_estimar_elasticidad.groupby('categoria_clusterizacion_numerica')['Plazo_Simulado'].transform('mean')\n",
    "df_estimar_elasticidad['Plazo_Simulado_min'] = df_estimar_elasticidad.groupby('categoria_clusterizacion_numerica')['Plazo_Simulado'].transform('min')\n",
    "df_estimar_elasticidad['Plazo_Simulado_max'] = df_estimar_elasticidad.groupby('categoria_clusterizacion_numerica')['Plazo_Simulado'].transform('max')\n",
    "df_estimar_elasticidad['Plazo_Simulado_mode'] = df_estimar_elasticidad.groupby('categoria_clusterizacion_numerica')['Plazo_Simulado'].transform(lambda x: x.mode().iloc[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar solo las columnas necesarias del DataFrame 'df_estimar_elasticidad' para reducir su tamaño\n",
    "# 'df_estimar_elasticidad_small' contiene las columnas esenciales para el análisis:\n",
    "# 'categoria_clusterizacion_numerica', 'rut', 'tasa_optima', 'probabilidad_aceptacion_optima', 'Probabilidad_No_Pago',\n",
    "# 'Monto_Simulado_mean', y 'Plazo_Simulado_mean'.\n",
    "df_estimar_elasticidad_small = df_estimar_elasticidad[['categoria_clusterizacion_numerica', 'rut', 'tasa_optima', 'probabilidad_aceptacion_optima', 'Probabilidad_No_Pago', \n",
    "                                                       'Monto_Simulado_mean',\n",
    "                                                       'Plazo_Simulado_mean', 'Plazo_Simulado_min', 'Plazo_Simulado_max', 'Plazo_Simulado_mode']]\n",
    "\n",
    "# Seleccionar solo las columnas necesarias del DataFrame 'df_probabilities' para reducir su tamaño\n",
    "# 'df_probabilities_small' contiene las columnas 'categoria_clusterizacion_numerica', 'probabilidad_simular', y 'Tratamiento'.\n",
    "df_probabilities_small = df_probabilities[['categoria_clusterizacion_numerica', 'probabilidad_simular', 'Tratamiento']]\n",
    "\n",
    "# Realizar un merge entre 'df_estimar_elasticidad_small' y 'df_probabilities_small' usando 'categoria_clusterizacion_numerica' como clave\n",
    "# Esta unión ('how=\"left\"') mantiene todas las filas de 'df_estimar_elasticidad_small' y añade la información de 'df_probabilities_small'\n",
    "# cuando hay coincidencias en 'categoria_clusterizacion_numerica'. El resultado se guarda en 'df_asignacion_de_tratamientos'.\n",
    "df_asignacion_de_tratamientos = pd.merge(df_estimar_elasticidad_small, df_probabilities_small, on='categoria_clusterizacion_numerica', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un nombre de carpeta con una marca de tiempo actual\n",
    "# 'strftime' genera la fecha y hora actual en el formato \"YYYYMMDD_HHMMSS\".\n",
    "# Esto se usa para crear una carpeta única 'folder_name' donde se guardarán los archivos.\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "folder_name = f\"cluster_data_{timestamp}\"\n",
    "os.makedirs(folder_name, exist_ok=True)  # Crear la carpeta; 'exist_ok=True' evita errores si ya existe.\n",
    "\n",
    "# Guardar información de los clusters\n",
    "# Seleccionar las columnas relevantes sobre cada cluster desde 'df_estimar_elasticidad_small' y eliminar duplicados.\n",
    "# El DataFrame 'df_cluster_info' contiene datos únicos de cada cluster como el monto y plazo medio simulado, la probabilidad de aceptación óptima y la tasa óptima.\n",
    "df_cluster_info = df_estimar_elasticidad_small[['categoria_clusterizacion_numerica', 'probabilidad_aceptacion_optima', 'tasa_optima',\n",
    "                                                'Monto_Simulado_mean',\n",
    "                                                'Plazo_Simulado_mean', 'Plazo_Simulado_min', 'Plazo_Simulado_max', 'Plazo_Simulado_mode']].drop_duplicates()\n",
    "df_cluster_info.to_csv(f\"{folder_name}/cluster_info.csv\", index=False)\n",
    "\n",
    "# Guardar las probabilidades y tratamiento\n",
    "# Seleccionar columnas relevantes de 'df_probabilities_small' para almacenar la probabilidad de simulación y tratamiento asignado para cada cluster.\n",
    "# 'df_probabilities_treatment' contiene esta información única por cada combinación de cluster y tratamiento.\n",
    "df_probabilities_treatment = df_probabilities_small[['categoria_clusterizacion_numerica', 'probabilidad_simular', 'Tratamiento']].drop_duplicates()\n",
    "df_probabilities_treatment.to_csv(f\"{folder_name}/probabilities_treatment.csv\", index=False)\n",
    "\n",
    "# Guardar información del RUT\n",
    "# Seleccionar columnas clave sobre cada cliente ('rut') desde 'df_estimar_elasticidad_small' y eliminar duplicados.\n",
    "# 'df_rut_info' contiene el 'rut', la categoría de cluster y la probabilidad de no pago para cada cliente, sin registros duplicados.\n",
    "df_rut_info = df_estimar_elasticidad_small[['rut', 'categoria_clusterizacion_numerica', 'Probabilidad_No_Pago']].drop_duplicates()\n",
    "df_rut_info.to_csv(f\"{folder_name}/rut_info.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Modelo de asignacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo de asignacion que itera por cliente (FLEXIBLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and processing probabilities data...\n",
      "Merging probabilities with rut_info...\n",
      "Merging rut_info with cluster_info...\n",
      "Calculating RC...\n",
      "Adding cluster flexibility constraints...\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (win64 - Windows 10.0 (19045.2))\n",
      "\n",
      "CPU model: AMD Ryzen 5 2500U with Radeon Vega Mobile Gfx, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 4892872 rows, 4349304 columns and 14678673 nonzeros\n",
      "Model fingerprint: 0xf754c549\n",
      "Variable types: 0 continuous, 4349304 integer (4349304 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+04, 8e+05]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 2e+05]\n",
      "Presolve removed 0 rows and 0 columns (presolve time = 5s) ...\n",
      "Presolve removed 0 rows and 0 columns (presolve time = 11s) ...\n",
      "Presolve removed 0 rows and 0 columns (presolve time = 16s) ...\n",
      "Presolve removed 0 rows and 0 columns (presolve time = 20s) ...\n",
      "Presolve removed 0 rows and 0 columns (presolve time = 25s) ...\n",
      "Presolve removed 0 rows and 0 columns (presolve time = 31s) ...\n",
      "Presolve removed 0 rows and 0 columns (presolve time = 35s) ...\n",
      "Presolve removed 0 rows and 0 columns (presolve time = 40s) ...\n",
      "Presolve removed 0 rows and 0 columns (presolve time = 45s) ...\n",
      "Presolve removed 0 rows and 0 columns (presolve time = 50s) ...\n",
      "Presolve removed 0 rows and 0 columns (presolve time = 55s) ...\n",
      "Presolve removed 0 rows and 0 columns (presolve time = 60s) ...\n",
      "Presolve removed 0 rows and 0 columns (presolve time = 65s) ...\n",
      "Presolve removed 0 rows and 0 columns (presolve time = 71s) ...\n",
      "Presolve time: 73.37s\n",
      "Presolved: 4892872 rows, 4349304 columns, 14678673 nonzeros\n",
      "Variable types: 0 continuous, 4349304 integer (4349304 binary)\n",
      "Found heuristic solution: objective 8.409295e+10\n",
      "Deterministic concurrent LP optimizer: primal simplex, dual simplex, and barrier\n",
      "Showing barrier log only...\n",
      "\n",
      "Root barrier log...\n",
      "\n",
      "Elapsed ordering time = 5s\n",
      "Ordering time: 7.42s\n",
      "\n",
      "Barrier statistics:\n",
      " Dense cols : 96\n",
      " AA' NZ     : 1.087e+07\n",
      " Factor NZ  : 6.850e+07 (roughly 4.0 GB of memory)\n",
      " Factor Ops : 9.919e+08 (roughly 1 second per iteration)\n",
      " Threads    : 2\n",
      "\n",
      "                  Objective                Residual\n",
      "Iter       Primal          Dual         Primal    Dual     Compl     Time\n",
      "   0   6.58087436e+13  1.02571988e+11  1.31e+08 1.91e+05  2.10e+07   186s\n",
      "   1   5.88981483e+13  3.18713478e+11  1.16e+08 1.03e+03  9.73e+06   192s\n",
      "   2   4.92398923e+12  3.39359800e+11  9.53e+06 5.92e-05  8.68e+05   199s\n",
      "   3   1.10216542e+11  3.29895251e+11  1.95e-14 8.36e-05  1.68e+04   206s\n",
      "   4   1.25309468e+11  1.47491276e+11  4.44e-16 2.28e-05  1.70e+03   219s\n",
      "   5   1.33444287e+11  1.40004340e+11  1.62e-14 6.80e-06  5.03e+02   229s\n",
      "   6   1.36384384e+11  1.38018866e+11  4.88e-15 1.43e-06  1.25e+02   238s\n",
      "   7   1.36916021e+11  1.37782281e+11  2.44e-15 1.42e-06  6.64e+01   245s\n",
      "\n",
      "Barrier performed 7 iterations in 244.98 seconds (73.33 work units)\n",
      "Barrier solve interrupted - model solved by another algorithm\n",
      "\n",
      "Concurrent spin time: 13.66s (can be avoided by choosing Method=3)\n",
      "\n",
      "Solved with dual simplex\n",
      "\n",
      "Root simplex log...\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "  330425    1.3756720e+11   0.000000e+00   0.000000e+00    247s\n",
      "\n",
      "Root relaxation: objective 1.375672e+11, 330425 iterations, 105.87 seconds (26.96 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "*    0     0               0    1.375672e+11 1.3757e+11  0.00%     -  247s\n",
      "\n",
      "Explored 1 nodes (330425 simplex iterations) in 249.29 seconds (75.83 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 2: 1.37567e+11 8.4093e+10 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.375672020845e+11, best bound 1.375672020845e+11, gap 0.0000%\n",
      "Extracting results...\n",
      "\n",
      "Tratamientos asignados por cluster:\n",
      "Cluster 0: Tratamientos 5\n",
      "Cluster 1: Tratamientos 5\n",
      "Cluster 2: Tratamientos 5\n",
      "Cluster 3: Tratamientos 8\n",
      "Cluster 4: Tratamientos 5\n",
      "Cluster 5: Tratamientos 5, 8\n",
      "Cluster 6: Tratamientos 5\n",
      "Cluster 7: Tratamientos 8\n",
      "Cluster 8: Tratamientos 5\n",
      "Cluster 9: Tratamientos 5\n",
      "Cluster 10: Tratamientos 5\n",
      "Cluster 11: Tratamientos 8\n",
      "\n",
      "Ganancias totales: 137567202084.48\n",
      "\n",
      "Executives used: 205000\n",
      "Executives remaining: 0\n",
      "Optimization complete.\n"
     ]
    }
   ],
   "source": [
    "# Complete Optimized Code: Data Processing and Optimization\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from gurobipy import Model, GRB, quicksum\n",
    "\n",
    "# -------------------------------\n",
    "# Data Processing and Preprocessing\n",
    "# -------------------------------\n",
    "\n",
    "tratamiento_map = {\n",
    "    \"Ejecutivo=0, Correos=0\": 1, \"Ejecutivo=0, Correos=1\": 2,\n",
    "    \"Ejecutivo=0, Correos=2\": 3, \"Ejecutivo=0, Correos=3\": 4,\n",
    "    \"Ejecutivo=0, Correos=4\": 5, \"Ejecutivo=1, Correos=0\": 6,\n",
    "    \"Ejecutivo=1, Correos=1\": 7, \"Ejecutivo=1, Correos=2\": 8\n",
    "}\n",
    "\n",
    "# Parameters\n",
    "costosms = 100\n",
    "capacidad_ejecutivos = 205000\n",
    "\n",
    "# Step 1: Load and map 'tratamiento_id' in the probabilities data\n",
    "print(\"Loading and processing probabilities data...\")\n",
    "df_probabilities = df_probabilities_treatment\n",
    "df_probabilities['tratamiento_id'] = df_probabilities['Tratamiento'].map(tratamiento_map)\n",
    "\n",
    "# Step 2: Create 'tratamientos' list y merge con rut_info\n",
    "print(\"Merging probabilities with rut_info...\")\n",
    "df_probabilities['tratamientos'] = df_probabilities[['probabilidad_simular', 'tratamiento_id']].values.tolist()\n",
    "grouped_prob = df_probabilities.groupby('categoria_clusterizacion_numerica')['tratamientos'].apply(list).reset_index()\n",
    "\n",
    "df_rut_info = df_rut_info\n",
    "df_rut_info = df_rut_info.merge(grouped_prob, on='categoria_clusterizacion_numerica', how='left')\n",
    "df_rut_info.drop(columns='tratamientos_y')\n",
    "df_rut_info.rename(columns={'tratamientos_x': 'tratamientos'})\n",
    "\n",
    "# Step 3: Merge rut_info with cluster_info\n",
    "print(\"Merging rut_info with cluster_info...\")\n",
    "df_cluster_info = df_cluster_info\n",
    "df_rut_info = df_rut_info.merge(df_cluster_info, on='categoria_clusterizacion_numerica', how='left')\n",
    "\n",
    "# Step 4: Calculate 'RC'\n",
    "print(\"Calculating RC...\")\n",
    "df_rut_info['tasa_optima'] /= 100\n",
    "df_rut_info['RC'] = (\n",
    "    (df_rut_info['Plazo_Simulado_mean'] * df_rut_info['Monto_Simulado_mean'] * df_rut_info['tasa_optima'] *\n",
    "     ((1 + df_rut_info['tasa_optima']) ** df_rut_info['Plazo_Simulado_mean'])) /\n",
    "    (((1 + df_rut_info['tasa_optima']) ** df_rut_info['Plazo_Simulado_mean']) - 1)\n",
    ") - df_rut_info['Monto_Simulado_mean']\n",
    "\n",
    "# -------------------------------\n",
    "# Data Preparation for Optimization\n",
    "# -------------------------------\n",
    "\n",
    "# Convert 'tratamientos' to numpy array to improve indexing performance\n",
    "profits = np.array([\n",
    "    [\n",
    "        (row['RC'] * (1 - row['Probabilidad_No_Pago']) * row['probabilidad_aceptacion_optima'] * row['tratamientos'][t][0]) - \n",
    "        (row['tratamientos'][t][1] * costosms)\n",
    "        for t in range(len(row['tratamientos']))\n",
    "    ]\n",
    "    for _, row in df_rut_info.iterrows()\n",
    "])\n",
    "\n",
    "# Initialize model\n",
    "model = Model(\"Maximizar_Ganancias\")\n",
    "model.ModelSense = GRB.MAXIMIZE\n",
    "\n",
    "# Create decision variables and set objective\n",
    "n_clients, n_treatments = profits.shape\n",
    "variables = {}\n",
    "\n",
    "for i in range(n_clients):\n",
    "    variables[i] = {}\n",
    "    for t in range(n_treatments):\n",
    "        if profits[i, t] > 0:\n",
    "            variables[i][t] = model.addVar(vtype=GRB.BINARY, name=f\"x_{i}_{t}\")\n",
    "\n",
    "model.setObjective(\n",
    "    quicksum(variables[i][t] * profits[i, t] for i in variables for t in variables[i])\n",
    ")\n",
    "\n",
    "# Constraint: Each client receives exactly one treatment\n",
    "for i in variables:\n",
    "    model.addConstr(quicksum(variables[i].values()) == 1, name=f\"OneTreatmentPerClient_{i}\")\n",
    "\n",
    "# Capacity constraint for executives\n",
    "model.addConstr(\n",
    "    quicksum(variables[i][t] for i in variables for t in variables[i] if t in [5, 6, 7]) <= capacidad_ejecutivos,\n",
    "    name=\"CapacityConstraint\"\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# Cluster Flexibility: Allow Multiple Treatments per Cluster\n",
    "# -------------------------------\n",
    "\n",
    "print(\"Adding cluster flexibility constraints...\")\n",
    "\n",
    "# Definir el número máximo de tratamientos permitidos por clúster\n",
    "max_tratamientos_por_cluster = 2  # Puedes ajustar este valor según tus necesidades\n",
    "\n",
    "clusters = df_rut_info.groupby(\"categoria_clusterizacion_numerica\").indices\n",
    "for cluster_id, indices_cluster in clusters.items():\n",
    "    indices_list = list(indices_cluster)\n",
    "    \n",
    "    # Crear variables binarias para tratamientos por clúster\n",
    "    tratamientos_cluster = {}\n",
    "    for t in range(n_treatments):\n",
    "        tratamientos_cluster[t] = model.addVar(vtype=GRB.BINARY, name=f\"y_{cluster_id}_{t}\")\n",
    "    \n",
    "    # Vincular variables de tratamiento de cliente con tratamientos del clúster\n",
    "    for i in indices_list:\n",
    "        for t in variables[i]:\n",
    "            # Si el tratamiento t es asignado al cliente i, entonces el tratamiento t debe estar asignado al clúster\n",
    "            model.addConstr(variables[i][t] <= tratamientos_cluster[t], name=f\"LinkCluster_{cluster_id}_Client_{i}_Treatment_{t}\")\n",
    "    \n",
    "    # Limitar el número de tratamientos por clúster\n",
    "    model.addConstr(\n",
    "        quicksum(tratamientos_cluster[t] for t in tratamientos_cluster) <= max_tratamientos_por_cluster,\n",
    "        name=f\"MaxTratamientosCluster_{cluster_id}\"\n",
    "    )\n",
    "\n",
    "# -------------------------------\n",
    "# Optimize the model\n",
    "# -------------------------------\n",
    "\n",
    "# Optimize the model\n",
    "model.optimize()\n",
    "\n",
    "# Check if the optimization was successful\n",
    "if model.Status == GRB.OPTIMAL:\n",
    "    # -------------------------------\n",
    "    # Extracting and Displaying Results\n",
    "    # -------------------------------\n",
    "    print(\"Extracting results...\")\n",
    "\n",
    "    # Asignar tratamientos por clúster basados en los resultados de la optimización\n",
    "    resultados_por_cluster = {}\n",
    "    for cluster_id, indices_cluster in clusters.items():\n",
    "        tratamientos_asignados = []\n",
    "        for t in range(n_treatments):\n",
    "            tratamiento_var = model.getVarByName(f\"y_{cluster_id}_{t}\")\n",
    "            if tratamiento_var.X > 0.5:\n",
    "                tratamientos_asignados.append(t)\n",
    "        resultados_por_cluster[cluster_id] = tratamientos_asignados\n",
    "\n",
    "    # Calcular ganancias totales\n",
    "    ganancias_totales = model.ObjVal\n",
    "\n",
    "    # Mostrar resultados\n",
    "    print(\"\\nTratamientos asignados por cluster:\")\n",
    "    for cluster_id, tratamientos in resultados_por_cluster.items():\n",
    "        tratamientos_str = ', '.join([str(t + 1) for t in tratamientos])\n",
    "        print(f\"Cluster {cluster_id}: Tratamientos {tratamientos_str}\")\n",
    "\n",
    "    print(f\"\\nGanancias totales: {ganancias_totales:.2f}\")\n",
    "\n",
    "    # -------------------------------\n",
    "    # Calculating Executive Usage\n",
    "    # -------------------------------\n",
    "    \n",
    "    # Contar el número de ejecutivos usados para tratamientos 5, 6 y 7\n",
    "    executives_used = sum(\n",
    "        1 for i in variables for t in variables[i] if t in [5, 6, 7] and variables[i][t].X > 0.5\n",
    "    )\n",
    "    executives_remaining = capacidad_ejecutivos - executives_used\n",
    "\n",
    "    # Mostrar resumen del uso de ejecutivos\n",
    "    print(f\"\\nExecutives used: {executives_used}\")\n",
    "    print(f\"Executives remaining: {executives_remaining}\")\n",
    "\n",
    "else:\n",
    "    print(\"Optimization did not reach an optimal solution.\")\n",
    "print(\"Optimization complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rut</th>\n",
       "      <th>assigned_treatment</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543646</th>\n",
       "      <td>543647</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543647</th>\n",
       "      <td>543648</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543648</th>\n",
       "      <td>543649</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543649</th>\n",
       "      <td>543650</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543650</th>\n",
       "      <td>543651</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>543651 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           rut  assigned_treatment  cluster\n",
       "0            1                   5        0\n",
       "1            2                   5        4\n",
       "2            3                   8        7\n",
       "3            4                   5        0\n",
       "4            5                   5        8\n",
       "...        ...                 ...      ...\n",
       "543646  543647                   5        4\n",
       "543647  543648                   5        5\n",
       "543648  543649                   5        9\n",
       "543649  543650                   5        9\n",
       "543650  543651                   5        8\n",
       "\n",
       "[543651 rows x 3 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Suponiendo que 'variables' es un diccionario de diccionarios donde variables[i][t] es una variable Gurobi\n",
    "# y que 'df_rut_info' contiene las columnas 'rut' y 'categoria_clusterizacion_numerica'\n",
    "\n",
    "# Extraer las columnas necesarias como arrays para acceso más rápido\n",
    "ruts = df_rut_info['rut'].values\n",
    "clusters = df_rut_info['categoria_clusterizacion_numerica'].values\n",
    "\n",
    "# Crear una lista de tuplas con las asignaciones utilizando list comprehension\n",
    "asignaciones = [\n",
    "    (ruts[i], t + 1, clusters[i])\n",
    "    for i, t_dict in variables.items()\n",
    "    for t, var in t_dict.items()\n",
    "    if var.X > 0.5\n",
    "]\n",
    "\n",
    "# Convertir la lista de tuplas en un DataFrame\n",
    "df_asignaciones = pd.DataFrame(asignaciones, columns=['rut', 'assigned_treatment', 'cluster'])\n",
    "\n",
    "df_asignaciones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Conteo de asignaciones por clúster y tratamiento:\n",
      "assigned_treatment      5      8\n",
      "cluster                         \n",
      "0                   40091      0\n",
      "1                   52062      0\n",
      "2                   12994      0\n",
      "3                       0  19546\n",
      "4                   49057      0\n",
      "5                   11961  61545\n",
      "6                   27065      0\n",
      "7                       0  82671\n",
      "8                   54307      0\n",
      "9                   69628      0\n",
      "10                  21486      0\n",
      "11                      0  41238\n"
     ]
    }
   ],
   "source": [
    "# Contar asignaciones por clúster y tratamiento\n",
    "tratamiento_cluster_counts = df_asignaciones.groupby(['cluster', 'assigned_treatment']).size().unstack(fill_value=0)\n",
    "\n",
    "# Mostrar el resultado\n",
    "print(\"\\nConteo de asignaciones por clúster y tratamiento:\")\n",
    "print(tratamiento_cluster_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rut</th>\n",
       "      <th>assigned_treatment</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543646</th>\n",
       "      <td>543647</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543647</th>\n",
       "      <td>543648</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543648</th>\n",
       "      <td>543649</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543649</th>\n",
       "      <td>543650</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543650</th>\n",
       "      <td>543651</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>543651 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           rut  assigned_treatment  cluster\n",
       "0            1                   5        0\n",
       "1            2                   5        4\n",
       "2            3                   8        7\n",
       "3            4                   5        0\n",
       "4            5                   5        8\n",
       "...        ...                 ...      ...\n",
       "543646  543647                   5        4\n",
       "543647  543648                   5        5\n",
       "543648  543649                   5        9\n",
       "543649  543650                   5        9\n",
       "543650  543651                   5        8\n",
       "\n",
       "[543651 rows x 3 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_asignaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "543639\n",
      "543639\n"
     ]
    }
   ],
   "source": [
    "print(df_asignaciones['cluster'].duplicated().sum())  # Count duplicates in 'cluster'\n",
    "print(df_rut_info['categoria_clusterizacion_numerica'].duplicated().sum())  # Count duplicates in 'categoria_clusterizacion_numerica'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rut_merge = df_rut_info[['rut', 'tratamientos', 'categoria_clusterizacion_numerica', 'Probabilidad_No_Pago', 'probabilidad_aceptacion_optima',\t'tasa_optima',\t'Monto_Simulado_mean',\t'Plazo_Simulado_mean',\t'Plazo_Simulado_min',\t'Plazo_Simulado_max',\t'Plazo_Simulado_mode']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rut_merge.rename(columns = {'categoria_clusterizacion_numerica': 'cluster'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_assigned = pd.merge(\n",
    "    df_asignaciones,\n",
    "    df_rut_merge,\n",
    "    how='left'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_assigned.drop(columns = {'categoria_clusterizacion_numerica'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la probabilidad de simulación para el tratamiento asignado en cada fila de 'df_assigned'\n",
    "# Se usa 'apply' con una función lambda para extraer la probabilidad de simulación correspondiente al tratamiento asignado.\n",
    "# 'row['tratamientos']' es una lista de opciones de tratamiento y 'row['assigned_treatment'] - 1' indica la posición del tratamiento.\n",
    "# Primero, se verifica que 'tratamientos' sea una lista y que el índice calculado esté dentro del rango.\n",
    "# Si estas condiciones se cumplen, se extrae la probabilidad de simulación; en caso contrario, se asigna None.\n",
    "df_assigned['probabilidad_de_simular'] = df_assigned.apply(\n",
    "    lambda row: row['tratamientos'][row['assigned_treatment'] - 1][0] \n",
    "                if isinstance(row['tratamientos'], list) and (0 <= row['assigned_treatment'] - 1 < len(row['tratamientos'])) \n",
    "                else None,\n",
    "    axis=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file saved in folder: assigned_treatments/assignation_20241117_140420\\assigned_treatments.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Crear una carpeta con un nombre basado en la fecha y hora actual\n",
    "# 'strftime' genera un timestamp en el formato \"YYYYMMDD_HHMMSS\" para asegurar nombres de carpeta únicos.\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "folder_name = f\"assigned_treatments/assignation_{timestamp}\"\n",
    "os.makedirs(folder_name, exist_ok=True)  # Crear la carpeta; 'exist_ok=True' evita errores si la carpeta ya existe.\n",
    "\n",
    "# Definir la ruta del archivo CSV dentro de la nueva carpeta\n",
    "output_path = os.path.join(folder_name, 'assigned_treatments.csv')\n",
    "\n",
    "# Guardar el DataFrame 'df_assigned' con las columnas seleccionadas en un archivo CSV\n",
    "# Se incluyen las columnas clave: 'rut', 'cluster', 'Probabilidad_No_Pago', 'RC', 'assigned_treatment',\n",
    "# 'probabilidad_de_simular', 'tasa_optima' y 'probabilidad_aceptacion_optima'.\n",
    "df_assigned[['rut', 'cluster', 'Probabilidad_No_Pago', 'assigned_treatment', 'probabilidad_de_simular', 'tasa_optima', 'probabilidad_aceptacion_optima']].to_csv(output_path, index=False)\n",
    "\n",
    "# Imprimir mensaje de confirmación con la ubicación del archivo CSV guardado\n",
    "print(f\"CSV file saved in folder: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo de asignacion que itera por cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and processing probabilities data...\n",
      "Merging probabilities with rut_info...\n",
      "Merging rut_info with cluster_info...\n",
      "Calculating RC...\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (win64 - Windows 10.0 (19045.2))\n",
      "\n",
      "CPU model: AMD Ryzen 5 2500U with Radeon Vega Mobile Gfx, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 13 rows, 96 columns and 132 nonzeros\n",
      "Model fingerprint: 0x0e4446d3\n",
      "Variable types: 0 continuous, 96 integer (96 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 8e+04]\n",
      "  Objective range  [2e+08, 6e+10]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 2e+05]\n",
      "Warning: Model contains large objective coefficients\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Found heuristic solution: objective 6.275927e+10\n",
      "Presolve removed 12 rows and 84 columns\n",
      "Presolve time: 0.01s\n",
      "Presolved: 1 rows, 12 columns, 12 nonzeros\n",
      "Found heuristic solution: objective 9.950115e+10\n",
      "Variable types: 0 continuous, 12 integer (12 binary)\n",
      "Found heuristic solution: objective 1.059835e+11\n",
      "\n",
      "Root relaxation: objective 1.378672e+11, 1 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 1.3787e+11    0    1 1.0598e+11 1.3787e+11  30.1%     -    0s\n",
      "H    0     0                    1.157384e+11 1.3787e+11  19.1%     -    0s\n",
      "H    0     0                    1.366935e+11 1.3787e+11  0.86%     -    0s\n",
      "\n",
      "Explored 1 nodes (1 simplex iterations) in 0.14 seconds (0.00 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 5: 1.36694e+11 1.15738e+11 1.05983e+11 ... 6.27593e+10\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.366935090221e+11, best bound 1.366935090221e+11, gap 0.0000%\n",
      "Extracting results...\n",
      "\n",
      "Tratamientos asignados por cluster:\n",
      "Cluster 0: Tratamiento 5\n",
      "Cluster 1: Tratamiento 5\n",
      "Cluster 2: Tratamiento 5\n",
      "Cluster 3: Tratamiento 5\n",
      "Cluster 4: Tratamiento 5\n",
      "Cluster 5: Tratamiento 8\n",
      "Cluster 6: Tratamiento 5\n",
      "Cluster 7: Tratamiento 8\n",
      "Cluster 8: Tratamiento 5\n",
      "Cluster 9: Tratamiento 5\n",
      "Cluster 10: Tratamiento 5\n",
      "Cluster 11: Tratamiento 8\n",
      "\n",
      "Ganancias totales: 136693509022.05\n",
      "\n",
      "Executives used: 197415\n",
      "Executives remaining: 7585\n",
      "Optimization complete.\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# Procesamiento y preprocesamiento de datos\n",
    "# -------------------------------\n",
    "\n",
    "# Definir la carpeta base y el mapeo de tratamientos\n",
    "base_folder = \"cluster_data_20241106_020021/\"  # Carpeta donde se encuentran los archivos de datos\n",
    "tratamiento_map = {  # Mapeo de los tratamientos específicos a identificadores numéricos\n",
    "    \"Ejecutivo=0, Correos=0\": 1, \"Ejecutivo=0, Correos=1\": 2,\n",
    "    \"Ejecutivo=0, Correos=2\": 3, \"Ejecutivo=0, Correos=3\": 4,\n",
    "    \"Ejecutivo=0, Correos=4\": 5, \"Ejecutivo=1, Correos=0\": 6,\n",
    "    \"Ejecutivo=1, Correos=1\": 7, \"Ejecutivo=1, Correos=2\": 8\n",
    "}\n",
    "\n",
    "# Definir las rutas de los archivos\n",
    "probabilities_file = os.path.join(base_folder, \"probabilities_treatment.csv\")\n",
    "rut_info_file = os.path.join(base_folder, \"rut_info.csv\")\n",
    "cluster_info_file = os.path.join(base_folder, \"cluster_info.csv\")\n",
    "\n",
    "# Parámetros\n",
    "costosms = 100  # Costo de cada mensaje SMS\n",
    "capacidad_ejecutivos = 205000  # Capacidad máxima en términos de tiempo de los ejecutivos\n",
    "\n",
    "# Paso 1: Cargar y mapear 'tratamiento_id' en los datos de probabilidades\n",
    "print(\"Loading and processing probabilities data...\")\n",
    "df_probabilities = df_probabilities_treatment\n",
    "df_probabilities['tratamiento_id'] = df_probabilities['Tratamiento'].map(tratamiento_map)\n",
    "\n",
    "# Paso 2: Crear lista de tratamientos y combinar con rut_info\n",
    "print(\"Merging probabilities with rut_info...\")\n",
    "df_probabilities['tratamientos'] = df_probabilities[['probabilidad_simular', 'tratamiento_id']].values.tolist()\n",
    "grouped_prob = df_probabilities.groupby('categoria_clusterizacion_numerica')['tratamientos'].apply(list).reset_index()\n",
    "\n",
    "df_rut_info = df_rut_info\n",
    "df_rut_info = df_rut_info.merge(grouped_prob, on='categoria_clusterizacion_numerica', how='left')\n",
    "\n",
    "# Paso 3: Combinar rut_info con cluster_info\n",
    "print(\"Merging rut_info with cluster_info...\")\n",
    "df_cluster_info = df_cluster_info\n",
    "df_rut_info = df_rut_info.merge(df_cluster_info, on='categoria_clusterizacion_numerica', how='left')\n",
    "\n",
    "# Paso 3.5: Agrupar información por cluster en 'rut_info'\n",
    "# Agrupar por 'categoria_clusterizacion_numerica' y agregar según lo especificado\n",
    "df_grouped = df_rut_info.groupby('categoria_clusterizacion_numerica').agg({\n",
    "    'Probabilidad_No_Pago': 'mean',  # Promedio de probabilidad de no pago\n",
    "    'tratamientos': lambda x: list(x),  # Lista de opciones de tratamiento únicas en cada cluster\n",
    "    'Monto_Simulado_mean': 'mean',\n",
    "    'Plazo_Simulado_mean': 'mean',\n",
    "    'probabilidad_aceptacion_optima': 'mean',\n",
    "    'tasa_optima': 'mean',\n",
    "    'rut': 'count'  # Conteo del número de clientes ('rut') en cada cluster\n",
    "}).rename(columns={'rut': 'n_clientes'}).reset_index()\n",
    "\n",
    "# Paso 4: Calcular 'RC' (Revenue calculado)\n",
    "print(\"Calculating RC...\")\n",
    "df_grouped['tasa_optima'] /= 100  # Convertir tasa óptima a decimal\n",
    "df_grouped['RC'] = (\n",
    "    (df_grouped['Plazo_Simulado_mean'] * df_grouped['Monto_Simulado_mean'] * df_grouped['tasa_optima'] *\n",
    "     ((1 + df_grouped['tasa_optima']) ** df_grouped['Plazo_Simulado_mean'])) /\n",
    "    (((1 + df_grouped['tasa_optima']) ** df_grouped['Plazo_Simulado_mean']) - 1)\n",
    ") - df_grouped['Monto_Simulado_mean']\n",
    "\n",
    "# -------------------------------\n",
    "# Preparación de datos para optimización\n",
    "# -------------------------------\n",
    "\n",
    "# Convertir 'tratamientos' a un arreglo de numpy para mejorar la indexación\n",
    "# Desarrollar y preparar 'tratamientos' para indexación adecuada\n",
    "profits = np.array([\n",
    "    [\n",
    "        row['n_clientes'] * (row['RC'] * (1 - row['Probabilidad_No_Pago']) * row['probabilidad_aceptacion_optima'] * row['tratamientos'][0][t][0]) - \n",
    "        (row['tratamientos'][0][t][1] * costosms)\n",
    "        for t in range(8)\n",
    "    ]\n",
    "    for _, row in df_grouped.iterrows()\n",
    "])\n",
    "\n",
    "# Inicializar el modelo de optimización\n",
    "model = Model(\"Maximizar_Ganancias\")\n",
    "model.ModelSense = GRB.MAXIMIZE\n",
    "\n",
    "# Crear variables de decisión y definir el objetivo\n",
    "n_clients, n_treatments = profits.shape\n",
    "variables = {}\n",
    "\n",
    "for i in range(n_clients):\n",
    "    variables[i] = {}\n",
    "    for t in range(n_treatments):\n",
    "        if profits[i, t] > 0:\n",
    "            variables[i][t] = model.addVar(vtype=GRB.BINARY, name=f\"x_{i}_{t}\")\n",
    "\n",
    "model.setObjective(\n",
    "    quicksum(variables[i][t] * profits[i, t] for i in variables for t in variables[i])\n",
    ")\n",
    "\n",
    "# Restricción: Cada cliente recibe exactamente un tratamiento\n",
    "for i in variables:\n",
    "    model.addConstr(quicksum(variables[i].values()) == 1, name=f\"OneTreatmentPerClient_{i}\")\n",
    "\n",
    "# Restricción de capacidad para ejecutivos\n",
    "model.addConstr(\n",
    "    quicksum(variables[i][t] * df_grouped.loc[i, 'n_clientes'] for i in variables for t in variables[i] if t in [5, 6, 7]) <= capacidad_ejecutivos,\n",
    "    name=\"CapacityConstraint\"\n",
    ")\n",
    "\n",
    "# Consistencia de cluster: los clientes dentro del mismo cluster deben recibir el mismo tratamiento\n",
    "clusters = df_grouped.groupby(\"categoria_clusterizacion_numerica\").indices\n",
    "for cluster_id, indices_cluster in clusters.items():\n",
    "    indices_list = list(indices_cluster)\n",
    "    leader_index = indices_list[0]\n",
    "    for t in variables[leader_index]:\n",
    "        leader_var = variables[leader_index][t]\n",
    "        for i in indices_list[1:]:\n",
    "            if t in variables[i]:\n",
    "                model.addConstr(variables[i][t] == leader_var, name=f\"ClusterConsistency_{cluster_id}_{t}\")\n",
    "\n",
    "# Optimizar el modelo\n",
    "model.optimize()\n",
    "\n",
    "# Verificar si la optimización fue exitosa\n",
    "if model.Status == GRB.OPTIMAL:\n",
    "    # -------------------------------\n",
    "    # Extracción y visualización de resultados\n",
    "    # -------------------------------\n",
    "\n",
    "    print(\"Extracting results...\")\n",
    "\n",
    "    # Asignar tratamientos por cluster basado en los resultados de la optimización\n",
    "    resultados_por_cluster = {}\n",
    "    for cluster_id, indices_cluster in clusters.items():\n",
    "        leader_index = list(indices_cluster)[0]\n",
    "        for t in variables[leader_index]:\n",
    "            if variables[leader_index][t].X > 0.5:\n",
    "                resultados_por_cluster[cluster_id] = t + 1\n",
    "                break\n",
    "\n",
    "    # Calcular las ganancias totales\n",
    "    ganancias_totales = model.ObjVal\n",
    "\n",
    "    # Mostrar resultados\n",
    "    print(\"\\nTratamientos asignados por cluster:\")\n",
    "    for cluster_id, tratamiento in resultados_por_cluster.items():\n",
    "        print(f\"Cluster {cluster_id}: Tratamiento {tratamiento}\")\n",
    "\n",
    "    print(f\"\\nGanancias totales: {ganancias_totales:.2f}\")\n",
    "\n",
    "    # Calcular el número de ejecutivos usados y restantes\n",
    "    executives_used = sum(\n",
    "        df_grouped.loc[i, 'n_clientes'] for i in variables for t in variables[i]\n",
    "        if t in [5, 6, 7] and variables[i][t].X > 0.5\n",
    "    )\n",
    "    executives_remaining = capacidad_ejecutivos - executives_used\n",
    "\n",
    "    # Mostrar resumen de uso de ejecutivos\n",
    "    print(f\"\\nExecutives used: {executives_used}\")\n",
    "    print(f\"Executives remaining: {executives_remaining}\")\n",
    "else:\n",
    "    print(\"Optimization did not reach an optimal solution.\")\n",
    "print(\"Optimization complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treatment 5: 9 times\n",
      "Treatment 8: 3 times\n"
     ]
    }
   ],
   "source": [
    "# Contar cuántas veces se asigna cada tratamiento en los resultados por cluster\n",
    "# Se utiliza un diccionario 'Counter' para contar las ocurrencias de cada tratamiento asignado en 'resultados_por_cluster'\n",
    "for cluster_id, tratamiento in resultados_por_cluster.items():\n",
    "    treatment_counts = Counter(resultados_por_cluster.values())\n",
    "\n",
    "# Imprimir el conteo de asignaciones para cada tratamiento\n",
    "# Se recorre 'treatment_counts' para mostrar cuántas veces se asignó cada tratamiento.\n",
    "# 'treatment + 1' se utiliza para mostrar el número de tratamiento en base 1, haciendo el resultado más legible.\n",
    "for treatment, count in treatment_counts.items():\n",
    "    print(f\"Treatment {treatment}: {count} times\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>assigned_treatment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cluster  assigned_treatment\n",
       "0         0                   5\n",
       "1         1                   5\n",
       "2         2                   5\n",
       "3         3                   5\n",
       "4         4                   5\n",
       "5         5                   8\n",
       "6         6                   5\n",
       "7         7                   8\n",
       "8         8                   5\n",
       "9         9                   5\n",
       "10       10                   5\n",
       "11       11                   8"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convertir el diccionario 'resultados_por_cluster' a un DataFrame\n",
    "# El diccionario 'resultados_por_cluster' contiene el ID del cluster y el tratamiento asignado a cada uno.\n",
    "# Se convierte a un DataFrame donde la primera columna es 'cluster' y la segunda 'assigned_treatment'.\n",
    "df_resultados_por_cluster = pd.DataFrame(list(resultados_por_cluster.items()), columns=[\"cluster\", \"assigned_treatment\"])\n",
    "\n",
    "# Mostrar el DataFrame resultante al usuario\n",
    "df_resultados_por_cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primer merge con 'df_rut_info'\n",
    "# Realizar una unión ('merge') entre 'df_resultados_por_cluster' y 'df_rut_info' usando 'cluster' en el primer DataFrame\n",
    "# y 'categoria_clusterizacion_numerica' en el segundo como claves de unión.\n",
    "# Esta unión permite agregar información de clientes a cada cluster con su tratamiento asignado.\n",
    "df_assigned = pd.merge(df_resultados_por_cluster, df_rut_info, left_on='cluster', right_on='categoria_clusterizacion_numerica', how='left')\n",
    "\n",
    "# Segundo merge con 'df_grouped' para agregar la columna 'RC'\n",
    "# Realizar una unión entre 'df_assigned' y 'df_grouped' para incorporar la columna 'RC' (Revenue Calculado)\n",
    "# Usamos 'categoria_clusterizacion_numerica' como clave de unión para añadir la información de revenue calculado a cada cluster.\n",
    "df_assigned = pd.merge(df_assigned, df_grouped[['categoria_clusterizacion_numerica', 'RC']], on='categoria_clusterizacion_numerica', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la probabilidad de simulación para el tratamiento asignado en cada fila de 'df_assigned'\n",
    "# Se usa 'apply' con una función lambda para extraer la probabilidad de simulación correspondiente al tratamiento asignado.\n",
    "# 'row['tratamientos']' es una lista de opciones de tratamiento y 'row['assigned_treatment'] - 1' indica la posición del tratamiento.\n",
    "# Primero, se verifica que 'tratamientos' sea una lista y que el índice calculado esté dentro del rango.\n",
    "# Si estas condiciones se cumplen, se extrae la probabilidad de simulación; en caso contrario, se asigna None.\n",
    "df_assigned['probabilidad_de_simular'] = df_assigned.apply(\n",
    "    lambda row: row['tratamientos'][row['assigned_treatment'] - 1][0] \n",
    "                if isinstance(row['tratamientos'], list) and (0 <= row['assigned_treatment'] - 1 < len(row['tratamientos'])) \n",
    "                else None,\n",
    "    axis=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file saved in folder: assigned_treatments/assignation_20241117_123829\\assigned_treatments.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Crear una carpeta con un nombre basado en la fecha y hora actual\n",
    "# 'strftime' genera un timestamp en el formato \"YYYYMMDD_HHMMSS\" para asegurar nombres de carpeta únicos.\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "folder_name = f\"assigned_treatments/assignation_{timestamp}\"\n",
    "os.makedirs(folder_name, exist_ok=True)  # Crear la carpeta; 'exist_ok=True' evita errores si la carpeta ya existe.\n",
    "\n",
    "# Definir la ruta del archivo CSV dentro de la nueva carpeta\n",
    "output_path = os.path.join(folder_name, 'assigned_treatments.csv')\n",
    "\n",
    "# Guardar el DataFrame 'df_assigned' con las columnas seleccionadas en un archivo CSV\n",
    "# Se incluyen las columnas clave: 'rut', 'cluster', 'Probabilidad_No_Pago', 'RC', 'assigned_treatment',\n",
    "# 'probabilidad_de_simular', 'tasa_optima' y 'probabilidad_aceptacion_optima'.\n",
    "df_assigned[['rut', 'cluster', 'Probabilidad_No_Pago', 'assigned_treatment', 'probabilidad_de_simular', 'tasa_optima', 'probabilidad_aceptacion_optima']].to_csv(output_path, index=False)\n",
    "\n",
    "# Imprimir mensaje de confirmación con la ubicación del archivo CSV guardado\n",
    "print(f\"CSV file saved in folder: {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
